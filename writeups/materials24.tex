\documentclass[11pt]{article}
\usepackage{amsmath, amsthm, amssymb,lscape, natbib}
\usepackage{mathtools}
\usepackage{subfigure}
\usepackage[font=footnotesize,labelfont=bf]{caption}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{hhline}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{setspace}
\usepackage[final]{pdfpages}
\usepackage[left=2.5cm,top=2.5cm,right=2.5cm, bottom=2.5cm]{geometry}
\usepackage{natbib} 
\usepackage{bibentry} 
\newcommand{\bibverse}[1]{\begin{verse} \bibentry{#1} \end{verse}}
\newcommand{\vs}{\vspace{.3in}}
\renewcommand{\ni}{\noindent}
\usepackage{xr-hyper}
\usepackage[]{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}
 
\urlstyle{same}
\usepackage[capposition=top]{floatrow}
\usepackage{amssymb}
\usepackage{relsize}
\usepackage[dvipsnames]{xcolor}
\usepackage{fancyhdr}
\usepackage{tikz}
 
\pagestyle{fancy} % customize header and footer
\fancyhf{} % clear initial header and footer
%\rhead{Overleaf}
\lhead{\centering \rightmark} % this adds subsection number and name
\lfoot{\centering \rightmark} 
\rfoot{\thepage} % put page number (the centering command puts it in the middle, don't matter if you put it in right or left footer)

\def \myFigPath {../figures/} 
% BE CAREFUL WITH FIGNAMES, IN LATEX THEY'RE NOT CASE SENSITIVE!!
\def \myTablePath {../tables/} 

%\definecolor{mygreen}{RGB}{0, 100, 0}
\definecolor{mygreen}{RGB}{0, 128, 0}

\definecolor{citec}{rgb}{0,0,.5}
\definecolor{linkc}{rgb}{0,0,.6}
\definecolor{bcolor}{rgb}{1,1,1}
\hypersetup{
%hidelinks = true
  colorlinks = true,
  urlcolor=linkc,
  linkcolor=linkc,
  citecolor = citec,
  filecolor = linkc,
  pdfauthor={Laura G\'ati},
}


\geometry{left=.83in,right=.89in,top=1in,
bottom=1in}
\linespread{1.5}
\renewcommand{\[}{\begin{equation}}
\renewcommand{\]}{\end{equation}}

% New Options
\newtheorem{prop}{Proposition}
\newtheorem{definition}{Definition}[section]
\newtheorem*{remark}{Remark}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{conjecture}{Conjecture}

%\newtheorem{theorem}{Theorem}[section] % the third argument specifies that their number will be adopted to the section
%\newtheorem{corollary}{Corollary}[theorem]
%\newtheorem{lemma}[theorem]{Lemma}
%\declaretheorem{proposition}
%\linespread{1.3}
%\raggedbottom
%\font\reali=msbm10 at 12pt

% New Commands
\newcommand{\real}{\hbox{\reali R}}
\newcommand{\realp}{\hbox{\reali R}_{\scriptscriptstyle +}}
\newcommand{\realpp}{\hbox{\reali R}_{\scriptscriptstyle ++}}
\newcommand{\R}{\mathbb{R}}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\argmin}{arg\,min}
\newcommand\w{3.0in}
\newcommand\wnum{3.0}
\def\myFigWidth{5.3in}
\def\mySmallerFigWidth{2.1in}
\def\myEvenBiggerFigScale{0.8}
\def\myPointSixFigScale{0.6}
\def\myBiggerFigScale{0.4}
\def\myFigScale{0.3}
\def\myMediumFigScale{0.25}
\def\mySmallFigScale{0.22}
\def\mySmallerFigScale{0.18}
\def\myTinyFigScale{0.16}
\def\myPointFourteenFigScale{0.14}
\def\myTinierFigScale{0.12}
\def\myAdjustableFigScale{0.16}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}} % this defines a command to make align only number this line
\newcommand{\code}[1]{\texttt{#1}} %code %

\renewcommand*\contentsname{Overview}
\setcounter{tocdepth}{2}

% define a command to make a huge question mark (it works in math mode)
\newcommand{\bigqm}[1][1]{\text{\larger[#1]{\textbf{?}}}}

\begin{document}

\linespread{1.0}

\title{Materials 24 - Implementing the target criterion (TC)}
\author{Laura G\'ati} 
\date{\today}
\maketitle

%%%%%%%%%%%%%%%%%%%%             DOCUMENT           %%%%%%%%%%%%%%%%%% 

\tableofcontents

%\listoffigures

\newpage
\section{Description of the three steps}
\textbf{Overall goal}: find an exogenous sequence $\{i_t\}_{t=1}^{T}$ that replaces the Taylor rule as a DGP for $i$ and implements the target criterion in the simplified anchoring model, equation (\ref{target}).\\
I proceed in 3 steps: \\
1) \emph{find an exogenous sequence $\{i_t\}_{t=1}^{T}$ that replaces the Taylor rule as a DGP for $i$ and fulfills the other model equations, w/o a target criterion;} \\
2) find an exogenous sequence $\{i_t\}_{t=1}^{T}$ that replaces the Taylor rule as a DGP for $i$ and fulfills the other model equations \emph{including a simple target criterion from the RE model with discretion;} \\
3) find an exogenous sequence $\{i_t\}_{t=1}^{T}$ that replaces the Taylor rule as a DGP for $i$ and fulfills the other model equations, \emph{including the anchoring target criterion.} \\
Variable dimensions in this exercise:
\begin{itemize}
\item The \# of exogenous sequences to feed in and optimize over: $\{i_t\}$, $\{i_t, x_t\}$ or $\{i_t, x_t, \pi_t\}$.
\item The \# of equations to consider as residual: none, (\ref{A9}), (\ref{A9}) and (\ref{A10}) or (\ref{A9}), (\ref{A10}) \& TC.
\end{itemize}

\begin{enumerate}
\item ``Choosing exogenous sequences for the observables'' - the main logic of the exercise
\begin{itemize}
\item The system we are trying to solve can be summarized as:
\begin{align}
x_t & = -\sigma i_t + f^1(\text{expectations}) + f^2(\text{exogenous states}) \tag{A9} \\
\pi_t & = -\kappa x_t + f^3(\text{expectations}) + f^4(\text{exogenous states}) \tag{A10} \\
i_t & = \mathcal{N}(0,\sigma^2) \tag{exog. DGP for $i$}
\end{align}
\item I'll mark the given stuff in blue. In all of this exercise I treat the expectations equations as exactly fulfilled, so the above is
\begin{align}
x_t & = \textcolor{blue}{-\sigma i_t + f^1(\text{expectations}) + f^2(\text{exogenous states})} \tag{A9} \\
\pi_t & = -\kappa x_t + \textcolor{blue}{f^3(\text{expectations}) + f^4(\text{exogenous states})} \tag{A10} \\
i_t & = \textcolor{blue}{\mathcal{N}(0,\sigma_i^2)} \tag{exog. DGP for $i$}
\end{align}
\item What this shows is that if the i-DGP is exact, which it has to be, then A9 pins down $x_t$, and A10 pins down $\pi_t$, uniquely. I cannot treat anything as a residual equation, and since all $\{i_t\}$ fulfill this system, the initial guess is the solution, even if expectations blow up.
\item So if I want to add ``wiggle-room," and make say A9 residual, I need something else to pin down $x_t$; in other words, I need to feed in (and optimize over) an exogenous sequence of $x$:
\begin{align}
res_{A9}& = \textcolor{blue}{- x_t -\sigma i_t + f^1(\text{expectations}) + f^2(\text{exogenous states})} \tag{A9} \\
\pi_t & =   \textcolor{blue}{-\kappa x_t + f^3(\text{expectations}) + f^4(\text{exogenous states})} \tag{A10} \\
i_t & = \textcolor{blue}{\mathcal{N}(0,\sigma_i^2)} \tag{exog. DGP for $i$}\\
x_t & = \textcolor{blue}{\mathcal{N}(0,\sigma_x^2)} \tag{exog. DGP for $x$}
\end{align}
\item Similarly, the maximum I can do here is to feed in and optimize over $\pi$ as well:
\begin{align}
res_{A9}& = \textcolor{blue}{- x_t -\sigma i_t + f^1(\text{expectations}) + f^2(\text{exogenous states})} \tag{A9} \\
res_{A10}& =   \textcolor{blue}{-\pi_t  -\kappa x_t + f^3(\text{expectations}) + f^4(\text{exogenous states})} \tag{A10} \\
i_t & = \textcolor{blue}{\mathcal{N}(0,\sigma_i^2)} \tag{exog. DGP for $i$}\\
x_t & = \textcolor{blue}{\mathcal{N}(0,\sigma_x^2)} \tag{exog. DGP for $x$} \\
pi_t & = \textcolor{blue}{\mathcal{N}(0,\sigma_{\pi}^2)} \tag{exog. DGP for $\pi$}
\end{align}
\end{itemize}
\item ``Implementing the RE-discretion target criterion"
\begin{itemize}
\item The only thing that changes wrt. point 1 is that I add the TC as a model equation, with its own residual term. In terms of the first equation system above:
\begin{align}
x_t & = \textcolor{blue}{-\sigma i_t + f^1(\text{expectations}) + f^2(\text{exogenous states})} \tag{A9} \\
\pi_t & = -\kappa x_t + \textcolor{blue}{f^3(\text{expectations}) + f^4(\text{exogenous states})} \tag{A10} \\
i_t & = \textcolor{blue}{\mathcal{N}(0,\sigma_i^2)} \tag{exog. DGP for $i$} \\
\pi_t & = -\frac{\lambda_x}{\kappa} x_t \tag{RE-TC}
\end{align}
$\rightarrow$ the TC has to be a residual equation.
\end{itemize}
\item ``Implementing the simple anchoring target criterion''
\begin{itemize}
\item The only thing that changes wrt. point 1 is that I add the anchoring TC (eq. \ref{target}) as a model equation, with its own residual term. Since this requires a bunch of expected future terms, I evaluate its residual not at each simulation iteration $t$, but at the end, $T$. Also, I only evaluate $T-H$ residuals, so I can treat $H$ simulation periods as expectations.
\begin{align}
x_t & = \textcolor{blue}{-\sigma i_t + f^1(\text{expectations}) + f^2(\text{exogenous states})} \tag{A9} \\
\pi_t & = -\kappa x_t + \textcolor{blue}{f^3(\text{expectations}) + f^4(\text{exogenous states})} \tag{A10} \\
i_t & = \textcolor{blue}{\mathcal{N}(0,\sigma_i^2)} \tag{exog. DGP for $i$} \\
\pi_t & = -\frac{\lambda_x}{\kappa}x_t +\text{stuff}\times \E_t \sum_{h=1}^{H}f(x_{t+h}, \pi_{t+h}, s_{t+h}, k_{t+h}, \bar{\pi}_{t+h}, \mathbf{g}_{\bar{\pi}}(t+h) ) \tag{anchoring TC}
\end{align}
\end{itemize}
\end{enumerate}

\textbf{Questions/notes:}
\begin{enumerate}
\item I choose $\lambda_x = 0.5$ for these figures.
\item In order not to assume perfect foresight, I write $\E_t s_{t+h} = h_x^{h-1}s_t$ in the TC.
\item Could one optimize $t$-by-$t$? Normally, I think yes, with anchoring TC, I think no.
\item Solver stops prematurely (loss on order \texttt{e+03} or \texttt{e+08})
\item ``Value function iteration-equivalent'' solution method?
\item ``Spline-equivalent'' method of finding the optimal functional form that delivers the optimal sequence $\{i_t\}_{t=1}^T$? $\rightarrow$ a numerical approx to the optimal reaction function that replaces the TR.
\end{enumerate}



\newpage
\section{Choosing exogenous sequences for the observables}

\vspace{-0.2cm}

\begin{figure}[h!]
\subfigure[Inputs: $i$, residual eq.: none; initialized at TR]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq_iinitialized_atTR}}
\hfill
\subfigure[Same as (a), initialized at random sequence(s)]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq_i_initalized_at_rand}}
\subfigure[Inputs: $x,i$, residual eq.: A9; initialized at TR]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq_xiinitialized_atTR}}
\hfill
\subfigure[Same as (c), initialized at random sequence(s)]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq_xi_initalized_at_rand}}
\subfigure[Inputs: $\pi,x,i$, residual eq. A9, A10;  initialized at TR]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq__pixi_initialized_atTR}}
\hfill
\subfigure[Same as (e), initialized at random sequence(s)]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq__pixi_initalized_at_rand}}
\caption{Simulation using Taylor rule against exogenous sequences that minimize equation residuals}
\end{figure}
$\rightarrow$ I can implement the Tayor-rule-outcome without using a Taylor rule. (Conditional on initial sequences being the Taylor-rule-sequences.)

\newpage
\section{Implementing the RE-discretion target criterion}

\vspace{-0.2cm}

\begin{figure}[h!]
\subfigure[Inputs: $i$, residual eq.: TC.]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq_i_TC_initalized_atTR}}
\hfill
\subfigure[Same as (a), initialized at random sequence(s)]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq_i_TC_initalized_at_rand}}
\subfigure[Inputs: $x,i$, residual eq.: A9, TC.]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq_xi_TC_initalized_atTR}}
\hfill
\subfigure[Same as (c), initialized at random sequence(s)]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq_xi_TC_initalized_at_rand}}
\subfigure[Inputs: $\pi,x,i$, residual eq. A9, A10, TC.]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq__pixi_TC_initalized_atTR}}
\hfill
\subfigure[Same as (e), initialized at random sequence(s)]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq__pixi_TC_initalized_at_rand}}
\caption{Simulation using Taylor rule against exogenous sequences that minimize equation residuals including RE discretion target criterion}
\end{figure}




\newpage
\section{Implementing the simple anchoring target criterion}

\vspace{-0.2cm}

\begin{figure}[h!]
\subfigure[Inputs: $i$, residual eq.: TC.]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq_i_anch_TC_initalized_atTR}}
\hfill
\subfigure[Same as (a), initialized at random sequence(s)]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq_i_anch_TC_initalized_at_rand}}
\subfigure[Inputs: $x,i$, residual eq.: A9, TC.]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq_xi_anch_TC_initalized_atTR}}
\hfill
\subfigure[Same as (c), initialized at random sequence(s)]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq_xi_anch_TC_initalized_at_rand}}
\subfigure[Inputs: $\pi,x,i$, residual eq. A9, A10, TC.]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq__pixi_anch_TC_initalized_atTR}}
\hfill
\subfigure[Same as (e), initialized at random sequence(s)]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_sim_given_seq__pixi_anch_TC_initalized_at_rand}}
\caption{Simulation using Taylor rule against exogenous sequences that minimize equation residuals including the simple anchoring target criterion}
\end{figure}

\newpage
\textbf{Comparison of the three exercises with favorite specification}
\begin{figure}[h!]
\subfigure[No TC]{\includegraphics[scale=0.2]{\myFigPath command_sim_given_seq__pixi_initalized_at_rand}}
\hfill
\subfigure[RE-discretion TC]{\includegraphics[scale=0.2]{\myFigPath command_sim_given_seq__pixi_TC_initalized_at_rand}}
\hfill
\subfigure[Anchoring TC]{\includegraphics[scale=0.2]{\myFigPath command_sim_given_seq__pixi_anch_TC_initalized_at_rand}}
\caption{Optimizing over $\{\pi_t, x_t, i_t\}$, initialized at random sequences}
\end{figure}

\newpage
\section{A value function iteration attempt at finding the optimal interest-rate-sequence}
The planner chooses $\{\pi_t, x_t, i_t, f_{a,t},  f_{b,t}, \bar{\pi}_t, k_t^{-1}\}_{t=t_0}^{\infty}$ to minimize
\begin{align}
V(\mathbf{x}_t,t)& = \max -\bigg\{ (\pi_t^2 + \lambda_x x_t^2) + \beta \E_t V(\mathbf{x}_{t+1},t+1) \bigg\} \\
& \text{s.t. to model equations}
\end{align}
Model equations are:
 \begin{align}
 \pi_t & = \kappa x_t +(1-\alpha)\beta f_a(t) +\kappa\alpha\beta b_2 (I_3 - \alpha\beta h_x)^{-1}s_t +e_3(I_3 - \alpha\beta h_x)^{-1}s_t  \label{midsimple_first}\\
 x_t & = -\sigma i_t +\sigma f_b(t)  +  (1-\beta)b_2 (I_3 - \beta h_x)^{-1}s_t - \sigma\beta b_3 (I_3 - \beta h_x)^{-1}s_t +\sigma e_1(I_3 - \beta h_x)^{-1}s_t  \big) \\
 f_a(t) &= \frac{1}{1-\alpha\beta}\bar{\pi}_{t-1}  + b_1(I_3 - \alpha\beta h_x)^{-1}s_t  \\
 f_b(t) & = \frac{1}{1-\beta}\bar{\pi}_{t-1}  + b_1(I_3 - \beta h_x)^{-1}s_t  \\
 \bar{\pi}_{t} & = \bar{\pi}_{t-1} + k_t^{-1}\big(\pi_{t} -(\bar{\pi}_{t-1}+b_1 s_{t-1}) \big)     \\
 k_t^{-1} & = k_{t-1}^{-1}+ \mathbf{g}(\pi_t - \bar{\pi}_{t-1}-b_1 s_{t-1})  
 \label{midsimple_last}
\end{align}

\newpage
Let's substitute out $x_t, f_{a,t}$ and $f_{b,t}$, so that the state vector is simply $\mathbf{x}_t = (\bar{\pi}_t, k_t^{-1},r_t^n,u_t)'$.

The problem becomes to choose $\{\pi_t, i_t, \bar{\pi}_t, k_t^{-1}\}_{t=t_0}^{\infty}$ to minimize
\begin{align*}
V(\mathbf{x}_t,t)& = \max -\bigg\{ \pi_t^2 +  \lambda_x\sigma^2 i_t^2 +\lambda_x\frac{\sigma^2}{(1-\beta)^2}\bar{\pi}_{t-1}^2 -\lambda_x\frac{\sigma^2}{1-\beta}i_t \bar{\pi}_{t-1} \\
&-\lambda_x\sigma\bigg(\sigma b_1(I_3 - \beta h_x)^{-1}  +  (1-\beta)b_2 (I_3 - \beta h_x)^{-1} - \sigma\beta b_3 (I_3 - \beta h_x)^{-1} +\sigma e_1(I_3 - \beta h_x)^{-1}\bigg)i_ts_t\\
& + \lambda_x \frac{\sigma}{1-\beta}\bigg(\sigma b_1(I_3 - \beta h_x)^{-1}  +  (1-\beta)b_2 (I_3 - \beta h_x)^{-1} - \sigma\beta b_3 (I_3 - \beta h_x)^{-1} +\sigma e_1(I_3 - \beta h_x)^{-1}\bigg)\bar{\pi}_{t-1}s_t\\
& +\lambda_x\bigg(\sigma b_1(I_3 - \beta h_x)^{-1}  +  (1-\beta)b_2 (I_3 - \beta h_x)^{-1} - \sigma\beta b_3 (I_3 - \beta h_x)^{-1} +\sigma e_1(I_3 - \beta h_x)^{-1}\bigg)^2s_t \\
& + \beta \E_t V(\mathbf{x}_{t+1},t+1) \bigg\} \numberthis \\
& \text{s.t. to model equations}
\end{align*}
 \begin{align*}
 \pi_t & = -\kappa\sigma i_t +\bigg(\kappa\sigma \frac{1}{1-\beta} +  \frac{(1-\alpha)\beta}{1-\alpha\beta}\bigg)\bar{\pi}_{t-1}  \\
 & +\bigg(\kappa\sigma b_1(I_3 - \beta h_x)^{-1}   +  \kappa(1-\beta)b_2 (I_3 - \beta h_x)^{-1} - \kappa\sigma\beta b_3 (I_3 - \beta h_x)^{-1}+\kappa\sigma e_1(I_3 - \beta h_x)^{-1}   \\
 &  + (1-\alpha)\beta b_1(I_3 - \alpha\beta h_x)^{-1}  +\kappa\alpha\beta b_2 (I_3 - \alpha\beta h_x)^{-1} +e_3(I_3 - \alpha\beta h_x)^{-1}\bigg)s_t \\
 \bar{\pi}_{t} & = \bar{\pi}_{t-1} + k_t^{-1}\big(\pi_{t} -(\bar{\pi}_{t-1}+b_1 s_{t-1}) \big)   \numberthis  \\
 k_t^{-1} & = k_{t-1}^{-1}+ \mathbf{g}(\pi_t - \bar{\pi}_{t-1}-b_1 s_{t-1})  \numberthis
\end{align*}






\newpage
\appendix
% the following command makes equation numbering include the section first, but just for what follows
\numberwithin{equation}{section}
\section{Model summary}

\vspace{-0.5cm}

\begin{align}
x_t &=  -\sigma i_t +\hat{\E}_t \sum_{T=t}^{\infty} \beta^{T-t }\big( (1-\beta)x_{T+1} - \sigma(\beta i_{T+1} - \pi_{T+1}) +\sigma r_T^n \big)  \label{prestons18}  \\
\pi_t &= \kappa x_t +\hat{\E}_t \sum_{T=t}^{\infty} (\alpha\beta)^{T-t }\big( \kappa \alpha \beta x_{T+1} + (1-\alpha)\beta \pi_{T+1} + u_T\big) \label{prestons19}  \\
i_t &= \psi_{\pi}\pi_t + \psi_{x} x_t  + \bar{i}_t \label{TR} \quad \quad (\text{if imposed})
\end{align}

\vspace{-1.2cm}

\begin{align}
\text{PLM:} \quad \quad & \hat{\E}_t z_{t+h}  =  a_{t-1} + bh_x^{h-1}s_t  \quad \forall h\geq 1 \quad \quad b = g_x\; h_x \quad \quad  \label{PLM} \\
\text{Updating:} \quad \quad & a_{t}  =a_{t-1} +k_t^{-1}\big(z_{t} -(a_{t-1}+b s_{t-1}) \big)  \\
\text{Anchoring function:} \quad \quad & k_t  = k_{t-1} + \mathbf{g}(fe_{t-1}^2) \\
\text{Forecast error:} \quad \quad & fe_{t-1}  = z_t - (a_{t-1}+b s_{t-1})\\
\text{LH expectations:} \quad \quad & f_a(t) = \frac{1}{1-\alpha\beta}a_{t-1}  + b(\mathbb{I}_{nx} - \alpha\beta h)^{-1}s_t \quad \quad  f_b(t) = \frac{1}{1-\beta}a_{t-1}  + b(\mathbb{I}_{nx} - \beta h)^{-1}s_t  \label{fafb_anal}
\end{align}

\vspace{-0.5cm}

This notation captures vector learning ($z$ learned) for intercept only. For scalar learning, $a_t= \begin{pmatrix} \bar{\pi}_t & 0 & 0\end{pmatrix}' $ and $b_1$ designates the first row of $b$. The observables $(\pi, x)$ are determined as:
\begin{align}
x_t &=  -\sigma i_t + \begin{bmatrix} \sigma & 1-\beta & -\sigma\beta \end{bmatrix} f_b + \sigma \begin{bmatrix} 1 & 0 & 0 \end{bmatrix} (\mathbb{I}_{nx} - \beta h_x)^{-1} s_t \label{A9} \\
\pi_t &= \kappa x_t  + \begin{bmatrix} (1-\alpha)\beta & \kappa\alpha\beta & 0 \end{bmatrix}  f_a + \begin{bmatrix} 0 & 0 & 1 \end{bmatrix}  (\mathbb{I}_{nx} - \alpha \beta h_x)^{-1}  s_t \label{A10}
\end{align}

\section{Target criterion}\label{target_crit_levels}
The target criterion in the simplified model (scalar learning of inflation intercept only, $k_t^{-1} = \mathbf{g}(fe_{t-1})$):
\begin{align*}
\pi_t  = -\frac{\lambda_x}{\kappa}\bigg\{x_t - \frac{(1-\alpha)\beta}{1-\alpha\beta} \bigg(k_t^{-1}+((\pi_t - \bar{\pi}_{t-1}-b_1 s_{t-1}))\mathbf{g}_{\pi}(t) \bigg) \\
\bigg(\E_t\sum_{i=1}^{\infty}x_{t+i}\prod_{j=0}^{i-1}(1-k_{t+1+j}^{-1} - (\pi_{t+1+j} - \bar{\pi}_{t+j}-b_1 s_{t+j})\mathbf{g_{\bar{\pi}}}(t+j)) \bigg)
\bigg\} \numberthis \label{target}
\end{align*}
where I'm using the notation that $\prod_{j=0}^{0} \equiv 1$. For interpretation purposes, let me rewrite this as follows:
\begin{align*}
\pi_t  = & \; \textcolor{red}{-\frac{\lambda_x}{\kappa} x_t} \textcolor{blue}{ \; + \frac{\lambda_x}{\kappa} \frac{(1-\alpha)\beta}{1-\alpha\beta} \bigg(k_t^{-1}+ fe^{eve}_{t|t-1}\mathbf{g}_{\pi}(t) \bigg)\E_t\sum_{i=1}^{\infty}x_{t+i}}  \\
& \textcolor{mygreen}{- \frac{\lambda_x}{\kappa} \frac{(1-\alpha)\beta}{1-\alpha\beta} \bigg(k_t^{-1}+ fe^{eve}_{t|t-1}\mathbf{g}_{\pi}(t) \bigg) \bigg(\E_t\sum_{i=1}^{\infty}x_{t+i}\prod_{j=0}^{i-1}(k_{t+1+j}^{-1} + fe^{eve}_{t+1+j|t+j})\mathbf{g_{\bar{\pi}}}(t+j) \bigg)}
\numberthis \label{target_interpretation}
\end{align*}
Interpretation: \textcolor{red}{tradeoffs from discretion in RE} + \textcolor{blue}{effect of current level and change of the gain on future tradeoffs} + \textcolor{mygreen}{effect of future expected levels and changes of the gain on future tradeoffs}

\section{A target criterion system for an anchoring function specified for gain changes}\label{target_crit_changes}
\begin{equation}
k_t = k_{t-1} + \mathbf{g}(fe_{t|t-1})
\end{equation}
Turns out the $k_{t-1}$ adds one $\varphi_{6,t+1}$ too many which makes the target criterion unwieldy. The FOCs of the Ramsey problem are
\begin{align}
& 2\pi_t + 2\frac{\lambda}{\kappa}x_t -k_t^{-1} \varphi_{5,t} - \mathbf{g}_{\pi}(t)\varphi_{6,t}  = 0 \label{gaspar22}\\
& c x_{t+1} + \varphi_{5,t} -(1-k_t^{-1})\varphi_{5,t+1} +\mathbf{g}_{\bar{\pi}}(t)\varphi_{6,t+1} = 0 \label{gaspar21}\\
& \varphi_{6,t} \; \textcolor{red}{+\; \varphi_{6,t+1}} = fe_t \varphi_{5,t} \label{constraints}
\end{align}
where the red multiplier is the new element vis-a-vis the case where the anchoring function is specified in levels ($k_t^{-1} = \mathbf{g}(fe_{t-1})$, as in App. \ref{target_crit_levels}), and I'm using the shorthand notation
\begin{align}
c & = -\frac{2(1-\alpha)\beta}{1-\alpha\beta}\frac{\lambda}{\kappa} \\ 
fe_t & = \pi_t - \bar{\pi}_{t-1}-b s_{t-1}
\end{align}
(\ref{gaspar22}) says that in anchoring, the discretion tradeoff is complemented with tradeoffs coming from learning ($\varphi_{5,t}$), which are more binding when expectations are unanchored ($k_{t}^{-1}$ high). Moreover, the change in the anchoring of expectations imposes an additional constraint ($\varphi_{6,t}$), which is more strongly binding if the gain responds strongly to inflation ($\mathbf{g}_{\pi}(t)$).
One can simplify this three-equation-system to:
\begin{align}
\varphi_{6,t} & = -c fe_t x_{t+1} + \bigg(1+ \frac{fe_t}{fe_{t+1}}(1-k_{t+1}^{-1}) -fe_t \mathbf{g}_{\bar{\pi}}(t) \bigg) \varphi_{6,t+1} -\frac{fe_t}{fe_{t+1}}(1-k_{t+1}^{-1})\varphi_{6,t+2}\label{6'} \\
0 & = 2\pi_t + 2\frac{\lambda}{\kappa}x_t   - \bigg( \frac{k_t^{-1}}{fe_t} + \mathbf{g}_{\pi}(t)\bigg)\varphi_{6,t} + \frac{k_t^{-1}}{fe_t}\varphi_{6,t+1}\label{1'}
\end{align}
Unfortunately, I haven't been able to solve (\ref{6'}) for $\varphi_{6,t}$ and therefore I can't express the target criterion so nicely as before. The only thing I can say is to direct the targeting rule-following central bank to compute $\varphi_{6,t}$ as the solution to (\ref{1'}), and then evaluate (\ref{6'}) as a target criterion. The solution to (\ref{1'}) is given by:
\begin{equation}
\varphi_{6,t} = -2\E_t\sum_{i=0}^{\infty}(\pi_{t+i}+\frac{\lambda_x}{\kappa}x_{t+i})\prod_{j=0}^{i-1}\frac{\frac{k_{t+j}^{-1}}{fe_{t+j}}}{\frac{k_{t+j}^{-1}}{fe_{t+j}} + \mathbf{g}_{\pi}(t+j)} \label{sol1'}
\end{equation}
Interpretation: the anchoring constraint is not binding ($\varphi_{6,t}=0$) if the CB always hits the target (
$\pi_{t+i}+\frac{\lambda_x}{\kappa}x_{t+i} = 0 \quad \forall i$); or expectations are always anchored ($k_{t+j}^{-1}=0 \quad \forall j$). 


\end{document}

%%%%%%%%%%%%%    SUBFIGURE  %%%%%%%%%%%
%\begin{figure}[h!]
%\subfigure[Hodrick-Prescott, $\lambda=1600$]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath materials22_gain_dhat_HP}}
%\hfill % this is great to intro dpace between subfigures
%\subfigure[Hamilton, 4 lags, $h=8$]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath materials22_gain_dhat_Hamilton}}
%\subfigure[Baxter-King, $(6,32)$ quarters, truncation at 12 lags]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath materials22_gain_dhat_BK}}
%\caption{Inverse gain for $\hat{d}$ for the different filters}
%\end{figure}

%%%%%%%%%%%%%    TABLE  %%%%%%%%%%%
%\begin{center}
%\begin{table}[h!]
%\caption{$\hat{d}$}
%\begin{tabular}{ c |c |c }
%  & $W = I$ & $W = \text{diag}(\hat{\sigma}_{ac(0)}, \dots, \hat{\sigma}_{ac(K)})$ \\ 
%  \hline
% HP & 77.7899 & 10 \\  
% \hline
% Hamilton & 32.1649 & 10 \\  
% \hline
% BK & 90.3929 & 10    
%\end{tabular}
%\end{table}
%\end{center}





