\documentclass[11pt]{article}
\usepackage{amsmath, amsthm, amssymb,lscape, natbib}
\usepackage{mathtools}
\usepackage{subfigure}
\usepackage[font=footnotesize,labelfont=bf]{caption}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{hhline}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{setspace}
\usepackage[final]{pdfpages}
\usepackage[left=2.5cm,top=2.5cm,right=2.5cm, bottom=2.5cm]{geometry}
\usepackage{natbib} 
\usepackage{bibentry} 
\newcommand{\bibverse}[1]{\begin{verse} \bibentry{#1} \end{verse}}
\newcommand{\vs}{\vspace{.3in}}
\renewcommand{\ni}{\noindent}
\usepackage{xr-hyper}
\usepackage[]{hyperref}
\usepackage[capposition=top]{floatrow}
\usepackage{amssymb}


\def \myFigPath {../figures/} 
% BE CAREFUL WITH FIGNAMES, IN LATEX THEY'RE NOT CASE SENSITIVE!!
\def \myTablePath {../tables/} 

\definecolor{citec}{rgb}{0,0,.5}
\definecolor{linkc}{rgb}{0,0,.6}
\definecolor{bcolor}{rgb}{1,1,1}
\hypersetup{
%hidelinks = true
  colorlinks = true,
  urlcolor=linkc,
  linkcolor=linkc,
  citecolor = citec,
  filecolor = linkc,
  pdfauthor={Laura G\'ati},
}


\geometry{left=.83in,right=.89in,top=1in,
bottom=1in}
\linespread{1.5}
\renewcommand{\[}{\begin{equation}}
\renewcommand{\]}{\end{equation}}

% New Options
\newtheorem{prop}{Proposition}
\newtheorem{definition}{Definition}[section]
\newtheorem*{remark}{Remark}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
%\newtheorem{theorem}{Theorem}[section] % the third argument specifies that their number will be adopted to the section
%\newtheorem{corollary}{Corollary}[theorem]
%\newtheorem{lemma}[theorem]{Lemma}
%\declaretheorem{proposition}
%\linespread{1.3}
%\raggedbottom
%\font\reali=msbm10 at 12pt

% New Commands
\newcommand{\real}{\hbox{\reali R}}
\newcommand{\realp}{\hbox{\reali R}_{\scriptscriptstyle +}}
\newcommand{\realpp}{\hbox{\reali R}_{\scriptscriptstyle ++}}
\newcommand{\R}{\mathbb{R}}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\argmin}{arg\,min}
\newcommand\w{3.0in}
\newcommand\wnum{3.0}
\def\myFigWidth{5.3in}
\def\mySmallerFigWidth{2.1in}
\def\myEvenBiggerFigScale{0.8}
\def\myPointSixFigScale{0.6}
\def\myBiggerFigScale{0.4}
\def\myFigScale{0.3}
\def\mySmallFigScale{0.22}
\def\mySmallerFigScale{0.18}
\def\myTinyFigScale{0.16}
\def\myPointFourteenFigScale{0.14}
\def\myTinierFigScale{0.12}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}} % this defines a command to make align only number this line
\newcommand{\code}[1]{\texttt{#1}} %code %

\renewcommand*\contentsname{Overview}
\setcounter{tocdepth}{2}

\begin{document}

\linespread{1.0}

\title{Materials 3 - Special cases}
\author{Laura G\'ati} 
\date{\today}
\maketitle

%%%%%%%%%%%%%%%%%%%%             DOCUMENT           %%%%%%%%%%%%%%%%%% 

\tableofcontents

%\listoffigures

\newpage
\section{The models to be simulated}
\begin{enumerate}
\item Rational expectations NK model (RE)
\item Euler equation approach learning NK model \`a la Bullard \& Mitra (2002)  (EE)
\item LR expectations learning NK model \`a la Preston (2005)  (LR)
\item (Eventually: LR expectations learning NK model \`a la Preston with anchoring \`a la CEMP)
\end{enumerate}

The difference between these models is 1) in the expectations (rational or not), 2) in the number of horizons of expectations that need to be summed (1 vs. infinite). So what I'm going to do consists of 2 steps: 
\begin{enumerate}
\item Write a learning rule that takes the form of Preston's, but that nests CEMP, and has a decreasing gain.
\item Write out $f_a$ and $f_b$ as truncated sums of $h$-period ahead forecasts. When $h=1$, EE and LR (models (\ref{LOM_EE}) and (\ref{LOM_LR})) should coincide.
\end{enumerate}

\subsection{RE}
\begin{align}
x_t &= \E_t x_{t+1} - \sigma(i_t - \E_t \pi_{t+1}) +\sigma r_t^n \label{NKIS} \\
\pi_t &= \kappa x_t +\beta \E_t \pi_{t+1} + u_t  \label{NKPC} \\
i_t &= \bar{i}_t + \psi_{\pi}\pi_t + \psi_{x} x_t  \label{TR}
\end{align}
\subsection{EE}
\begin{align}
x_t &= \hat{\E}_t x_{t+1} - \sigma(i_t - \hat{\E}_t \pi_{t+1}) +\sigma r_t^n \tag{Preston, eq. (13)} \label{prestons13} \\
\pi_t &= \kappa x_t +\beta \hat{\E}_t \pi_{t+1} + u_t \tag{Preston, eq. (14)} \label{prestons14}  \\
i_t &= \bar{i}_t + \psi_{\pi}\pi_t + \psi_{x} x_t \tag{Preston, eq. (27) } 
\end{align}
\subsection{LR}
\begin{align}
x_t &=  -\sigma i_t +\hat{\E}_t \sum_{T=t}^{\infty} \beta^{T-t }\big( (1-\beta)x_{T+1} - \sigma(\beta i_{T+1} - \pi_{T+1}) +\sigma r_T^n \big) \tag{Preston, eq. (18)} \label{prestons18}  \\
\pi_t &= \kappa x_t +\hat{\E}_t \sum_{T=t}^{\infty} (\alpha\beta)^{T-t }\big( \kappa \alpha \beta x_{T+1} + (1-\alpha)\beta \pi_{T+1} + u_T\big)\tag{Preston, eq. (19)} \label{prestons19}  \\
i_t &= \psi_{\pi}\pi_t + \psi_{x} x_t + \bar{i}_t \tag{Preston, eq. (27)} 
\end{align}
One issue is that if I set $T=t$, I don't think \ref{prestons18} reduces to \ref{prestons13}, nor does \ref{prestons19} reduce to \ref{prestons14}.
 \section{Compact notation}
Exogenous states are summarized as:
 \begin{align*}
 s_t & = P s_{t-1} + \epsilon_t 
 \quad \text{where} \quad 
 s_t & \equiv \begin{pmatrix} r_t^n \\ \bar{i}_t \\ u_t 
 \end{pmatrix} \quad 
 P  \equiv \begin{pmatrix} \rho_r & 0 & 0 \\ 0& \rho_i & 0 \\ 0&0& \rho_u 
 \end{pmatrix}  \quad 
 \epsilon_t \equiv \begin{pmatrix}\varepsilon_t^{r} \\ \varepsilon_t^{i}  \\ \varepsilon_t^{u} 
 \end{pmatrix}  \quad  \text{and } \quad \Sigma  =  \begin{pmatrix} \sigma_r & 0 & 0 \\ 0& \sigma_i & 0 \\ 0&0& \sigma_u 
 \end{pmatrix} 
 \end{align*}
 Let $z_t$ summarize the endogenous variables as
 \begin{equation}
 z_t \equiv \begin{pmatrix} \pi_t \\ x_t \\ i_t
 \end{pmatrix}
 \end{equation}
 Then I can write the models compactly as
 \begin{align}
z_t & = A_p^{RE} \E_t z_{t+1} + A_s^{RE} s_t \label{LOM_RE} \\
z_t & = A_p^{RE} \hat{\E}_t z_{t+1} + A_s^{RE} s_t \label{LOM_EE} \\
z_t & = A_a^{LR} f_a + A_b^{LR} f_b + A_s^{LR} s_t \label{LOM_LR} \\
s_t & = P s_{t-1} + \epsilon_t \label{exog}
\end{align}
 where $f_a$ and $f_b$ capture discounted sums of expectations at all horizons of the endogenous states $z$ (following Preston, I refer to these objects as ``long-run expectations''):
  \begin{align}
f_a  \equiv  \hat{\E}_t\sum_{T=t}^{\infty} (\alpha\beta)^{T-t } z_{T+1} \quad \quad \quad \quad f_b  \equiv \hat{\E}_t\sum_{T=t}^{\infty} (\beta)^{T-t } z_{T+1} \label{fafb}
\end{align}
and the coefficient matrices are given by:
\begin{align}
A_p^{RE} & = \begin{pmatrix} \beta + \frac{\kappa\sigma}{w} (1-\psi_{\pi}\beta) & \frac{\kappa}{w} & 0\\
 \frac{\sigma}{w} (1-\psi_{\pi}\beta) & \frac{1}{w}& 0\\ 
\psi_{\pi}\big( \beta + \frac{\kappa\sigma}{w} (1-\psi_{\pi}\beta) \big) +\psi_x\frac{\sigma}{w} (1-\psi_{\pi}\beta)&  \psi_x (\frac{1}{w})+ \psi_{\pi} (\frac{\kappa}{w})& 0\end{pmatrix} \quad \\
A_s^{RE} &= \begin{pmatrix}   \frac{\kappa\sigma}{w}  &-\frac{\kappa\sigma}{w}  & 1-\frac{\kappa\sigma\psi_{\pi}}{w}\\
 \frac{ \sigma}{w} &  -\frac{\sigma}{w} & -\frac{\sigma\psi_{\pi}}{w}\\ 
 \psi_x( \frac{\sigma}{w}) + \psi_{\pi}( \frac{\kappa\sigma}{w}) & \psi_x(- \frac{\sigma}{w}) + \psi_{\pi}(- \frac{\kappa\sigma}{w}) +1 &  \psi_x(-\frac{\sigma\psi_{\pi}}{w}) + \psi_{\pi}( 1-\frac{\kappa\sigma\psi_{\pi}}{w})\end{pmatrix}  
\\
A_a^{LR} & = \begin{pmatrix} g_{\pi a} \\ g_{x a} \\ \psi_{\pi}g_{\pi a} + \psi_xg_{x a}
\end{pmatrix}
\quad A_b^{LR} = \begin{pmatrix} g_{\pi b} \\ g_{x b} \\ \psi_{\pi}g_{\pi b} + \psi_xg_{x b}
\end{pmatrix}
 \quad A_s^{LR} = \begin{pmatrix} g_{\pi s} \\ g_{x s} \\ \psi_{\pi}g_{\pi s} + \psi_xg_{x s} + \begin{bmatrix} 0 & 1& 0\end{bmatrix}
\end{pmatrix} \\
g_{\pi a} & =(1-\frac{\kappa\sigma\psi_{\pi}}{w} )  \begin{bmatrix}(1-\alpha)\beta, \kappa\alpha\beta, 0 \end{bmatrix} \\
g_{x a} & =  \frac{-\sigma\psi_{\pi}}{w} \begin{bmatrix}(1-\alpha)\beta, \kappa\alpha\beta, 0 \end{bmatrix}\\
g_{\pi b} & = \frac{\kappa}{w} \begin{bmatrix}\sigma(1-\beta\psi_{\pi}), (1-\beta-\beta\sigma\psi_x, 0 \end{bmatrix}\\
g_{x b} & = \frac{1}{w} \begin{bmatrix}\sigma(1-\beta\psi_{\pi}), (1-\beta-\beta\sigma\psi_x, 0 \end{bmatrix} \\
g_{\pi s} & = (1-\frac{\kappa\sigma\psi_{\pi}}{w} )\begin{bmatrix} 0&0&1 \end{bmatrix} (I_3 - \alpha\beta P)^{-1} -\frac{\kappa\sigma}{w}\begin{bmatrix} -1&1&0 \end{bmatrix} (I_3 -\beta P)^{-1}\\
g_{x s} & =  \frac{-\sigma\psi_{\pi}}{w} \begin{bmatrix} 0&0&1 \end{bmatrix}(I_3 - \alpha\beta P)^{-1}  -\frac{\sigma}{w}\begin{bmatrix} -1&1&0 \end{bmatrix}(I_3 -\beta P)^{-1}\\
w & = 1+\sigma\psi_x +\kappa\sigma\psi_{\pi}
\end{align}
\clearpage

 \section{Learning}

In Preston (2005), agents forecast the endogenous variables using the exogenous ones as
\begin{equation}
z_t = a_{t} + b_{t} s_{t} + \epsilon_t \quad  \tag{Preston, p. 101}
\end{equation}
which I suspect isn't precise about the timing. Therefore, I write a general PLM of the form
\begin{equation}
z_t = a_{t-2} + b_{t-2} s_{t-1} + \epsilon_t \quad  \label{generalPLM}
\end{equation}
and then $\phi_{t-2} = (a_{t-2}, b_{t-2})$, here $3\times4$, so that agents learn both a constant and a slope term. This means $\hat{\E}_t z_{t+1} = \phi_{t-1}\begin{bmatrix} 1 \\ s_{t} \end{bmatrix} $. Later, I will simplify here so that agents only learn about the constant, i.e. about CEMP's drift term, but forecast exogenous states rationally:
\begin{equation}
z_t = \bar{z}_{t-2} + s_{t-1} + \epsilon_t \label{PLM}  
\end{equation}
so that $\phi_{t-2} = \bar{z}_{t-2}$. I'm actually quite worried about the assumption that agents only learn about the constant because it seems like a permanent deviation from RE: might it screw up E-stability? 

Anticipated utility implies that
\begin{equation}
\hat{\E}_{t-1}{\phi_{t+h}} = \hat{\E}_{t-1}{\phi_{t}} \equiv \phi_{t-1} \quad \forall \; h\geq0 
\end{equation}
This is a little tricky. It doesn't only mean that agents today mistakenly believe that they will not update the forecasting rule. It also implies that the belief about $\phi_t$ was formed at $t-1$.
Assuming RE about the exogenous process and anticipated utility, $h$-horizon forecasts are constructed as:
\begin{equation}
\hat{\E}_t z_{t+h} = a_{t-1} + b_{t-1}P^{h-1}s_t  \quad \forall h\geq 1 \label{PLM_fcst_general}
\end{equation}
Or, if I assume that agents don't learn the slope, 
\begin{equation}
\hat{\E}_t z_{t+h} = \bar{z}_{t-1} + P^{h-1}s_t  \quad \forall h\geq 1 \label{PLM_fcst}
\end{equation}
and the regression coefficients are updated using (for now) a decreasing gain RLS algorithm:
\begin{align}
\phi_t  & = \bigg( \phi_{t-1}' + t^{-1} \mathbf{R_t^{-1}}\begin{bmatrix} \mathbf{1} \\ \mathbf{s_{t-1}} \end{bmatrix}\bigg(z_{t} - \phi_{t-1} \begin{bmatrix} 1 \\ s_{t-1} \end{bmatrix} \bigg)' \bigg)' \\
R_t &= R_{t-1} +  t^{-1} \bigg( \begin{bmatrix} 1 \\ s_{t-1} \end{bmatrix} \begin{bmatrix} 1 & s_{t-1} \end{bmatrix}  - R_{t-1} \bigg)
\end{align}
$R_t$ is $4\times 4$ and $\phi_t$ is $3 \times 4$. Three questions:
\begin{enumerate}
\item The forecast error $z_{t} - \phi_{t-1} \begin{bmatrix} 1 \\ s_{t-1} \end{bmatrix} $ has weird timing: I don't think agents ever carried out this forecast, because at time $t-1$, their forecast was $\hat{\E}_{t-1}z_{t}=\phi_{t-2}\begin{bmatrix} 1 \\ s_{t-1} \end{bmatrix}$. So the fcst $\phi_{t-1} \begin{bmatrix} 1 \\ s_{t-1} \end{bmatrix} $  seems to be $\hat{\E}_{t}z_{t}$, i.e. a forecast that they are just using to assess $\phi$, but never actually relied upon previously (let's refer to this forecast as the ``assessment forecast''; really it's actually a nowcast). Or?
\item The bold $\mathbf{R_t^{-1}}\begin{bmatrix} \mathbf{1} \\ \mathbf{s_{t-1}} \end{bmatrix}$ indicates a difference to CEMP's learning algorithm: these terms are missing in CEMP. Am I right in thinking that that's because in CEMP, agents only learn the constant, and so the data they use is 1 instead of $\begin{bmatrix} 1 \\ s_{t} \end{bmatrix}$, making $R_t = 1 \; \forall \;t$?
\item Can this formulation capture the special case that agents only learn about the constant? $\Leftrightarrow$ Following up on the previous point, it seems to me that when agents learn only the constant, then $\phi_t = \bar{z}_{t-1}$ and the learning algorithm boils down to
\begin{equation}
\bar{z}_{t} = \bar{z}_{t-1} +t^{-1}\underbrace{\big(z_{t} -(\bar{z}_{t-1}+s_{t-1}) \big)}_{\text{fcst error given assessment fcst using (\ref{PLM_fcst})} }
\end{equation}
\end{enumerate}
And a note: CEMP is a special case of this model, with the gain switching between decreasing and constant according to the anchoring mechanism. I'm leaving that out for the time being. 

\section{ALMs}
\subsection{RE}
With some abuse of terminology, call the state-space representation the ALM of the RE model:
\begin{align}
x_{t} & = hx \; x_{t-1} + \eta s_t \label{state_eq}\\
z_t & = gx \; x_t \label{obs_eq}
\end{align}
Then I can write the ``ALM" as
\begin{align}
z_t & = gx \; hx \; x_{t-1} + gx \; \eta s_t  \label{ALM_RE}
\end{align}
Since this ALM implies no constant, I initialize $\bar{z}_0$ as a $3\times1$ zero vector, and thus $\phi_0 = \begin{bmatrix} \bar{z}_0 & gx \; hx\end{bmatrix} $ (and $hx = P$ for the NK model). Analogously, I initialize $R$ as a $R_0 = \begin{bmatrix} 1 & \mathbf{0} \\ \mathbf{0} & \Sigma_x \end{bmatrix}$, where $\Sigma_x$ is the VC matrix of the states from the RE solution. For the case where agents only learn the constant, I still initialize $\bar{z}_0$ as a $3\times1$ zero vector (and $R$ drops).
\subsection{EE}
I just need to use (\ref{PLM_fcst_general}) to evaluate one-period ahead forecasts (for constant-learning only, (\ref{PLM_fcst})), and plug those into (\ref{LOM_EE}).

\subsection{LR}
Evaluate analytical ``LR expectations'' (\ref{fafb}) using the PLM (\ref{PLM_fcst_general}), 
\begin{equation}
f_a = \frac{1}{1-\alpha\beta}a_{t-1}  + b_{t-1}(I_3 - \alpha\beta P)^{-1}s_t \quad \quad \quad f_b = \frac{1}{1-\beta}a_{t-1}  + b_{t-1}(I_3 - \beta P)^{-1}s_t  \label{fafb_analytical_general}
\end{equation}

and plug them into (\ref{LOM_LR}). In the case where agents only learn the constant I use (\ref{PLM_fcst}):
\begin{equation}
f_a = \frac{1}{1-\alpha\beta}\bar{z}_{t-1}  + (I_3 - \alpha\beta P)^{-1}s_t \quad \quad \quad f_b = \frac{1}{1-\beta}\bar{z}_{t-1}  + (I_3 - \beta P)^{-1}s_t  \label{fafb_analytical}
\end{equation}
Alternatively I can evaluate each $h$-period ahead forecast individually using (\ref{PLM_fcst_general}), and then sum $H$ of these terms, discounting appropriately. Earlier, it seemed that already a $H=100$ is not a bad approximation of $\infty$-horizons, but now that only holds for $f_a$. For $f_b$ to be accurate, I need at least $H=10000$. Why? Does the fact that $\alpha\beta < \beta$ matter so much?



\section{Timeline in the learning models}
\begin{enumerate}
\item[] \underline{$t=0$}: Initialize $\phi_{t-1} = \phi_0$ at the RE solution.
\item[] For each $t$:
\item Evaluate expectations $t+s$ (the one-period ahead, ($s=1$) or the full 1 to $\infty$-period ahead $(s=1,\dots, \infty)$) given $\phi_{t-1}$ and states dated $t$
\item Evaluate ALM given expectations: ``today's observables are a function of expectations and today's state''
\item Update learning: $\phi_t = $ RLS of $\phi_{t-1}$ and fcst error between today's data and yesterday's forecast
\end{enumerate}

\section{Special cases towards general case: procedure}
\begin{enumerate}
\item Simulate RE model $\checkmark$
\item Simulate EE model where agents learn both slope and constant $\checkmark$
	\begin{itemize}
	\item Simulate using the ``implicit ALM": rearranging the expectational matrix equation that underlies the solution to the model, you obtain the simulated observables $z_t$ without explicitly writing out the ALM $\checkmark$
	\item Simulate using the ``explicit ALM", equation (\ref{LOM_EE}), plugging in expectations evaluated separately. $\checkmark$
	\item[] The cool thing is: when I do the above two steps, I obtain the same simulated observables, so I know I'm doing it correctly.
 	\end{itemize}
\item Simulate LR model where agents learn both slope and constant, extend horizons from 1 to $\infty$ $\checkmark$
\item Simulate EE model where agents learn only the constant $\checkmark$
\item Simulate LR model where agents learn only the constant, extend horizons from 1 to infinity $\checkmark$
\end{enumerate}

\newpage
\section{Simulations}	
\subsection{Learning slope and constant}
\begin{figure}[h!]
\subfigure[RE and EE models only, learning both slope and constant]{
\includegraphics[scale = \myFigScale]{\myFigPath materials3_observables_RE_EE_only}}
\subfigure[RE, EE and LR models, learning both slope and constant, analytical expectations]{
\includegraphics[scale = \myFigScale]{\myFigPath materials3_observables1}}
\caption{Comparing models}
\end{figure}

\newpage
\begin{figure}[h!]
\includegraphics[scale = \myBiggerFigScale]{\myFigPath materials3_horizons}
\caption{Comparing horizons}
\end{figure}

Takeaways:
\begin{enumerate}
\item EE learning converges to RE over time, confirming that it's correct. Does LR? It doesn't seem like it (at $T=100000$, it hasn't converged).
\item LR analytical and truncated expectations coincide for a large enough horizon ($H \sim 10000$)
\item Even for $H=1$, LR and EE don't coincide; I think this is because the equations do not map onto one another.
\end{enumerate}

\newpage
So is it the case that learning isn't converging in the LR model? \\
$\rightarrow$ No! It's clearly converging, albeit slowly, see next fig!

\begin{figure}[h!]
\includegraphics[scale = \myFigScale]{\myFigPath materials3_diffs_LR}
\caption{Convergence LR learning}
\end{figure}

\begin{figure}[h!]
\includegraphics[scale = \myFigScale]{\myFigPath materials3_diffs_LR_100000}
\caption{Convergence LR learning, $T = 100000$}
\end{figure}

See: clearly converging!  \\

... but, problematically...

\newpage

\begin{figure}[h!]
\includegraphics[scale = \myFigScale]{\myFigPath materials3_observables_RE_LR_last100}
\caption{RE and LR models, $T = 100000$, last 100 periods}
\end{figure}

... the LR model observables clearly aren't converging to the RE model, not even after 100,000 simulated periods! \\
But wait a second, look at what they're doing after a million periods...
\begin{figure}[h!]
\includegraphics[scale = \myFigScale]{\myFigPath materials3_observables_RE_LR_last100_millionperiods}
\caption{RE and LR models, $T = 100000$, last 100 periods}
\end{figure}

I don't believe it! They are converging ...! (Side note: here, max abs differences in $\phi$ are on the order of magnitude of $10^{-5}$.) After 2 million periods, they nearly overlap, but still not quite. (Diffs are at $10^{-6}$ now. That takes 4 min to run though!)

\newpage
\subsection{Learning constant only}

 \begin{figure}[h!]
\includegraphics[scale = \myFigScale]{\myFigPath materials3_observables_constant_last100_2millionperiods}
\caption{All models, $T = 200000$, last 100 periods}
\end{figure}
 
 As I feared, this doesn't look E-stable: even after 1 million periods, neither EE nor LR converges to the RE solution. And this is despite learning clearly converging: max abs differences in the constant are $<10^{-5}$. Or are they converging, just \emph{much} slower?
 
 Maybe I need to change the PLM such that it nests the REE. If under RE CHECK wheth
 
\end{document}



