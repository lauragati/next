\documentclass[11pt]{article}
\usepackage{amsmath, amsthm, amssymb,lscape, natbib}
\usepackage{mathtools}
\usepackage{subfigure}
\usepackage[font=footnotesize,labelfont=bf]{caption}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{hhline}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{setspace}
\usepackage[final]{pdfpages}
\usepackage[left=2.5cm,top=2.5cm,right=2.5cm, bottom=2.5cm]{geometry}
\usepackage{natbib} 
\usepackage{bibentry} 
\newcommand{\bibverse}[1]{\begin{verse} \bibentry{#1} \end{verse}}
\newcommand{\vs}{\vspace{.3in}}
\renewcommand{\ni}{\noindent}
\usepackage{xr-hyper}
\usepackage[]{hyperref}
\usepackage[capposition=top]{floatrow}
\usepackage{amssymb}

\def \myFigPath {../figures/} 
% BE CAREFUL WITH FIGNAMES, IN LATEX THEY'RE NOT CASE SENSITIVE!!
\def \myTablePath {../tables/} 

\definecolor{citec}{rgb}{0,0,.5}
\definecolor{linkc}{rgb}{0,0,.6}
\definecolor{bcolor}{rgb}{1,1,1}
\hypersetup{
%hidelinks = true
  colorlinks = true,
  urlcolor=linkc,
  linkcolor=linkc,
  citecolor = citec,
  filecolor = linkc,
  pdfauthor={Laura G\'ati},
}


\geometry{left=.83in,right=.89in,top=1in,
bottom=1in}
\linespread{1.5}
\renewcommand{\[}{\begin{equation}}
\renewcommand{\]}{\end{equation}}

% New Options
\newtheorem{prop}{Proposition}
\newtheorem{definition}{Definition}[section]
\newtheorem*{remark}{Remark}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
%\newtheorem{theorem}{Theorem}[section] % the third argument specifies that their number will be adopted to the section
%\newtheorem{corollary}{Corollary}[theorem]
%\newtheorem{lemma}[theorem]{Lemma}
%\declaretheorem{proposition}
%\linespread{1.3}
%\raggedbottom
%\font\reali=msbm10 at 12pt

% New Commands
\newcommand{\real}{\hbox{\reali R}}
\newcommand{\realp}{\hbox{\reali R}_{\scriptscriptstyle +}}
\newcommand{\realpp}{\hbox{\reali R}_{\scriptscriptstyle ++}}
\newcommand{\R}{\mathbb{R}}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\argmin}{arg\,min}
\newcommand\w{3.0in}
\newcommand\wnum{3.0}
\def\myFigWidth{5.3in}
\def\mySmallerFigWidth{2.1in}
\def\myEvenBiggerFigScale{0.8}
\def\myPointSixFigScale{0.6}
\def\myBiggerFigScale{0.4}
\def\myFigScale{0.3}
\def\mySmallFigScale{0.22}
\def\mySmallerFigScale{0.18}
\def\myTinyFigScale{0.16}
\def\myPointFourteenFigScale{0.14}
\def\myTinierFigScale{0.12}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}} % this defines a command to make align only number this line
\newcommand{\code}[1]{\texttt{#1}} %code %

\renewcommand*\contentsname{Overview}
\setcounter{tocdepth}{2}

\begin{document}

\linespread{1.0}

\title{Materials 5 - Points raised in DW presentation and after}
\author{Laura G\'ati} 
\date{\today}
\maketitle

%%%%%%%%%%%%%%%%%%%%             DOCUMENT           %%%%%%%%%%%%%%%%%% 

\tableofcontents

%\listoffigures

%\newpage

\section{The expectation operator $\hat{\E}$}

	\begin{itemize}
	\item \emph{Everyone} in the literature is happily differentiating through $\hat{\E}$ w/o any remark
	\item[] e.g. Evans \& Honkapohja (2001 and the papers), Preston (2005), Graham (2011)
	\item The only hint I've found in the literature and in  Evans \& Honkapohja (2001) is the following (Chapter 11): \\
	Suppose agents in the model are trying to form the expectation $\hat{\E}\big(G(y_{t+1},v_{t+1}) \big)$, where $y$ is a vector of  endogenous variables, $v$ a vector of shocks and $G$ is a nonlinear function.\\
	They don't know future values, but have access to past values $G(y_{j},v_{j}) \quad j=1,\dots,t$. \\
	Then a natural estimator is the sample mean, $\theta_t \equiv \frac{1}{t} \sum_{j=1}^t G(y_{j},v_{j}) $. \\
	E\&H never say this, but I'm thinking that the sample mean is a linear operator. It's a discrete and backward-looking approximation of the integral of all possible states. Thus differentiation w.r.t. variables of the problem $(y)$ should be fine.
	\end{itemize}
\section{Small deviations in $\pi$, large ones in $x$ (Susanto: ``show me IRFs from RE and the anchoring model")}
My playing around with the simulated model yields the following result: 
	\begin{prop} The degree to which inflation responds to expectational deviations from rational expectations (RE) depends on $\kappa$, the slope of the Phillips curve. A lower $\kappa$ means higher price rigidity and translates to current inflation responding less to expectation gaps.
	\end{prop}
	\begin{corollary}Whether expectation gaps between subjective and rational expectations show up in inflation or output depends on the value of $\kappa$. When nominal rigidities are high ($\kappa$ is low), money is strongly nonneutral, and thus output is the margin of adjustment. When prices are flexible, money is neutral and inflation is the margin of adjustment. 
	\end{corollary}
	
	 Do we see this result in the learning literature?
		\begin{itemize}
		\item No - most of the learning literature focuses on E-stability.
		\item Yes! A few studies that look at how NK models with learning actually behave obtain similar things, even if not quite the same. But my result seems more to be in the background, never explicit:
			\begin{enumerate}
			\item Orphanides \& Williams (2004) \\
			This just documents that learning reduces the persistence of inflation, and this is the more so the more aggressive monetary policy is on inflation. $\rightarrow$
			Inflation persistence literature?
			\begin{itemize}
			\item Idea that Phillips-curves only fit the data well if you include lagged inflation, and that models where inflation is forward-looking (like the NK model) have a hard time matching this.
			\item Data: inflation persistence was small midcentury, increased considerably between 1960-80, and is now decreasing. 
			\item But it seems like this literature concluded that the higher $\kappa$, the more inflation ``inherits'' the output gap persistence. 
			\item But it makes sense why learning is like the ``hybrid Phillips curve:" expectations enter as novel backward-looking components, introducing a novel channel of ``intrinsic'' inflation inertia (persistence).
			\end{itemize}

			\item Eusepi \& Preston (2018), Fig 4 \\
			This figure plots the weighted volatility $\sigma_{\pi}^2 + \lambda \sigma_x^2$ as a function of $\lambda$, the weight of the output gap in the central bank's loss function. This function is (for the most part) increasing in $\lambda$. Here, by coincidence, we learn that in general, $\sigma_x > \sigma_{\pi}$. That means that for their parameterization, expectational errors will show up more in output gap volatility than in inflation volatility. \\ 
			But this is already a step further, b/c it looks at the interplay of monetary policy and learning, whereas my result is purely about the dynamics of the economy, keeping monetary policy constant.
			\item Noah Williams (2003), Fig 2. \\
			This is the closest to my result: in an NK model with constant gain learning ($\rightarrow$ unanchored), $\pi$ responds less to a shock to the natural rate than $x$. 
			\end{enumerate}
			$\Rightarrow$ would need to investigate my result with IRFs. But IRFs for the learning world are tricky! Why? B/c $gx$ changes in every period after the impulse as outcomes affect expectations and those feed back into outcomes. 
		\end{itemize}
		So how do I try to generate IRFs for the learning world? \\
		For a simulation consisting of $T$ periods and h-horizon IRFs, redo the simulation $T-h$ times, each time increasing $t$ from $1\dots T-h$:
		\begin{enumerate}
		\item[1)] imposing the unit innovation at time $t$ and calling the thus simulated series $y^{sim,t}$;
		\item[2)] calculating the difference between the newly simulated series and the originally simulated series: $y^{sim,t} - y^{sim}$;
		\item[3)] Finally take an average of these differences. 
		\end{enumerate}
		This should be something like an expected generalized impulse response in the sense that it is invariant to at what time we impose the innovation. However, it is still conditioned on a specific shock sequence, which I plot as a reminder below:
\begin{figure}[h!]
\includegraphics[scale = \mySmallerFigScale]{\myFigPath materials5_observables1} 
\caption{The observables for the specific shock sequence}
\end{figure}		

\begin{figure}[h!]
\includegraphics[scale = \mySmallerFigScale]{\myFigPath materials5_gain_drift} 
\caption{Inverse gain and drift for the specific shock sequence}
\end{figure}			
		
\begin{figure}[h!]
\includegraphics[scale = \myFigScale]{\myFigPath materials5_IRFs_natrate} 
\caption{IRFs to a natural rate shock ($r^n$)}
\end{figure}		

\begin{figure}[h!]
\includegraphics[scale = \myFigScale]{\myFigPath materials5_IRFs_monpol} 
\caption{IRFs to a monetary policy shock ($\bar{i}$)}
\end{figure}	

\begin{figure}[h!]
\includegraphics[scale = \myFigScale]{\myFigPath materials5_IRFs_costpush} 
\caption{IRFs to a cost-push shock ($u$)}
\end{figure}
\clearpage	

Some thoughts on the IRFs:
\begin{itemize}
\item I replicate here my previous result: the bigger $\alpha$ i.e. lower $\kappa$, the more it is the output gap that is the margin of adjustment. This is less so for the impact of shocks, more for the dynamics after. 
\item In terms of deviations from RE, those are in general bigger for the output gap than inflation except for the monetary policy shock.
\item Responses on impact have the same sign as RE, but can reverse over time. 
\item In general learning seems to induce sluggishness and hump shapes - not a surprise given that learning introduces backward-lookingness into the model.
\item In terms of uncertainty, anchoring $>$ decreasing gain $>$ constant gain b/c it is in this order that the timing makes a difference. Of course b/c it all depends on how the gain changes.
\item Also not a surprise: the most extreme responses are the perpetual learning ones (always constant gain), while the closest to RE are the decreasing gain ones. 
\item The more constant gains, the more things overreact.
\item I get almost the same IRFs as Williams (2003), Fig 2, but for the learning models I have an overshooting going on that's absent in Williams (2003).
\end{itemize}

\section{SR FE as the anchoring criterion $\theta_t$ instead of subjective - objective expectations}
	\begin{itemize}
	\item  CEMP has 4 arguments for $\theta_t$ 
		\begin{enumerate}
		\item Stand-in for a whole class of misspecification tests that firms may be doing (w/o taking a stance on which one firms are using)
		\item An alternative calibrated model in which $\theta_t$ is instead a version of the CUSUM test for structural breaks (Brown, Durbin \& Evans 1975) when simulated a) yields almost identical results to their estimation with their $\theta_t$, b) however imposes a larger number of parameters, making the estimation exercise even more cumbersome than it already is. \\
		By the way, Pablo also told me to do everything in C++ (to get speedups). Opinions?
		\item Low-frequency movements are hard to detect in real time using just forecast errors.
		\item CEMP show that their $\theta_t$ can be written as a sum of forecast errors.
		\end{enumerate}
	\end{itemize}

Here's my short summary and replication (with some guesswork) of CEMP's CUSUM-test based alternative criterion:
\begin{enumerate}
\item Let $f_t$ denote the short-run forecast error, and $\omega_t$ firms' estimate of the FE variance.
\item Let $\kappa \in (0,1)$ and $\tilde{\theta}$ be the new threshold value for the criterion.
\item Then for some dubious initial $(\omega_0, \theta_0)$, let firms in every period estimate the criterion and the FEV as:
\begin{align}
 \omega_t & =  \omega_{t-1} + \kappa k_{t-1}^{-1}(f_t^2 -\omega_{t-1})\\
\theta_t & =  \theta_{t-1} + \kappa k_{t-1}^{-1}(f_t^2/\omega_t -\theta_{t-1})\
\end{align}
and set the gain endogenously as (CUSUM anchoring mechanism)
\begin{align}
k_t & = \mathbb{I}\times(k_{t-1}+1) + (1-\mathbb{I}) \times \bar{g}^{-1} \\
\mathbb{I} & = 1 \quad \text{if} \quad  \theta_t \leq \tilde{\theta}
\end{align}
\end{enumerate}


\begin{figure}[h!]
\includegraphics[scale = \myFigScale]{\myFigPath materials5_observables2} 
\caption{CEMP's criterion against the CUSUM criterion, $\kappa = 0.8, \tilde{\theta} = 1.6$}
\end{figure}
\begin{figure}[h!]
\includegraphics[scale = \myFigScale]{\myFigPath materials5_gain_drift2} 
\caption{CEMP's criterion against the CUSUM criterion, $\kappa = 0.8, \tilde{\theta} = 1.6$}
\end{figure}




\end{document}





