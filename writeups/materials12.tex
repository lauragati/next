\documentclass[11pt]{article}
\usepackage{amsmath, amsthm, amssymb,lscape, natbib}
\usepackage{mathtools}
\usepackage{subfigure}
\usepackage[font=footnotesize,labelfont=bf]{caption}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{hhline}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{setspace}
\usepackage[final]{pdfpages}
\usepackage[left=2.5cm,top=2.5cm,right=2.5cm, bottom=2.5cm]{geometry}
\usepackage{natbib} 
\usepackage{bibentry} 
\newcommand{\bibverse}[1]{\begin{verse} \bibentry{#1} \end{verse}}
\newcommand{\vs}{\vspace{.3in}}
\renewcommand{\ni}{\noindent}
\usepackage{xr-hyper}
\usepackage[]{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}
 
\urlstyle{same}
\usepackage[capposition=top]{floatrow}
\usepackage{amssymb}
\usepackage{relsize}
\usepackage[dvipsnames]{xcolor}
\usepackage{fancyhdr}
\usepackage{tikz}
 
\pagestyle{fancy} % customize header and footer
\fancyhf{} % clear initial header and footer
%\rhead{Overleaf}
\lhead{\centering \rightmark} % this adds subsection number and name
\lfoot{\centering \rightmark} 
\rfoot{\thepage} % put page number (the centering command puts it in the middle, don't matter if you put it in right or left footer)

\def \myFigPath {../figures/} 
% BE CAREFUL WITH FIGNAMES, IN LATEX THEY'RE NOT CASE SENSITIVE!!
\def \myTablePath {../tables/} 

%\definecolor{mygreen}{RGB}{0, 100, 0}
\definecolor{mygreen}{RGB}{0, 128, 0}

\definecolor{citec}{rgb}{0,0,.5}
\definecolor{linkc}{rgb}{0,0,.6}
\definecolor{bcolor}{rgb}{1,1,1}
\hypersetup{
%hidelinks = true
  colorlinks = true,
  urlcolor=linkc,
  linkcolor=linkc,
  citecolor = citec,
  filecolor = linkc,
  pdfauthor={Laura G\'ati},
}


\geometry{left=.83in,right=.89in,top=1in,
bottom=1in}
\linespread{1.5}
\renewcommand{\[}{\begin{equation}}
\renewcommand{\]}{\end{equation}}

% New Options
\newtheorem{prop}{Proposition}
\newtheorem{definition}{Definition}[section]
\newtheorem*{remark}{Remark}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{conjecture}{Conjecture}

%\newtheorem{theorem}{Theorem}[section] % the third argument specifies that their number will be adopted to the section
%\newtheorem{corollary}{Corollary}[theorem]
%\newtheorem{lemma}[theorem]{Lemma}
%\declaretheorem{proposition}
%\linespread{1.3}
%\raggedbottom
%\font\reali=msbm10 at 12pt

% New Commands
\newcommand{\real}{\hbox{\reali R}}
\newcommand{\realp}{\hbox{\reali R}_{\scriptscriptstyle +}}
\newcommand{\realpp}{\hbox{\reali R}_{\scriptscriptstyle ++}}
\newcommand{\R}{\mathbb{R}}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\argmin}{arg\,min}
\newcommand\w{3.0in}
\newcommand\wnum{3.0}
\def\myFigWidth{5.3in}
\def\mySmallerFigWidth{2.1in}
\def\myEvenBiggerFigScale{0.8}
\def\myPointSixFigScale{0.6}
\def\myBiggerFigScale{0.4}
\def\myFigScale{0.3}
\def\myMediumFigScale{0.25}
\def\mySmallFigScale{0.22}
\def\mySmallerFigScale{0.18}
\def\myTinyFigScale{0.16}
\def\myPointFourteenFigScale{0.14}
\def\myTinierFigScale{0.12}
\def\myAdjustableFigScale{0.14}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}} % this defines a command to make align only number this line
\newcommand{\code}[1]{\texttt{#1}} %code %

\renewcommand*\contentsname{Overview}
\setcounter{tocdepth}{2}

% define a command to make a huge question mark (it works in math mode)
\newcommand{\bigqm}[1][1]{\text{\larger[#1]{\textbf{?}}}}

\begin{document}

\linespread{1.0}

\title{Materials 12 - tinkering around with policy and expectation formation \\
An informational assumption question}
\author{Laura G\'ati} 
\date{\today}
\maketitle

%%%%%%%%%%%%%%%%%%%%             DOCUMENT           %%%%%%%%%%%%%%%%%% 

\tableofcontents

%\listoffigures

\newpage
\section{Model summary}
\begin{align}
x_t &=  -\sigma i_t +\hat{\E}_t \sum_{T=t}^{\infty} \beta^{T-t }\big( (1-\beta)x_{T+1} - \sigma(\beta i_{T+1} - \pi_{T+1}) +\sigma r_T^n \big)  \label{prestons18}  \\
\pi_t &= \kappa x_t +\hat{\E}_t \sum_{T=t}^{\infty} (\alpha\beta)^{T-t }\big( \kappa \alpha \beta x_{T+1} + (1-\alpha)\beta \pi_{T+1} + u_T\big) \label{prestons19}  \\
i_t &= \psi_{\pi}\pi_t + \psi_{x} x_t  + \textcolor{red}{\big(\rho i_{t-1}\big)} + \bar{i}_t \label{TR}
\end{align}
\begin{equation}
\hat{\E}_t z_{t+h} =  \begin{bmatrix}\bar{\pi}_{t-1} \\ 0 \\ 0 \end{bmatrix}+ bh_x^{h-1}s_t  \quad \forall h\geq 1 \quad \quad b = g_x \; h_x \quad \quad \text{PLM} \label{PLM}
\end{equation}
\begin{equation}
\bar{\pi}_{t} = \bar{\pi}_{t-1} +k_t^{-1}\underbrace{\big(\pi_{t} -(\bar{\pi}_{t-1}+b_1s_{t-1}) \big)}_{\text{fcst error using (\ref{PLM})} } \quad \quad  \text{($b_1$ is the first row of $b$)}
\end{equation}
 \begin{align*}
k_t & = \begin{cases} k_{t-1}+1 \quad \text{for decreasing gain learning}  \\ \bar{g}^{-1}  \quad \text{for constant gain learning.}\numberthis
\end{cases} 
\end{align*}

\newpage
\section{Four quick changes}\label{changes}
\subsection{Quick overview $\blacktriangleleft$}
\begin{enumerate}
\item To policy
\begin{enumerate}
\item Check the fake $\psi_{\pi} < 1$ exercise.
\end{enumerate}
\item To expectation formation
\begin{enumerate}
\item Curiosity: check IRFs from Euler equation learning
\item IRFs from vector learning (meaning learn all observables)
\item Learning slope too, not just constant
\end{enumerate}
\end{enumerate}

What do they do:
\begin{enumerate}
\item $\psi_{\pi} \leq 1$: indeed kills the overshooting, but - no surprise - makes observables unstable (IRFs don't return to steady state). Why does it work to kill the overshooting? B/c the Ball-effect of anticipated interest rate reactions no longer overweighs (less expectational feedback).
\item Townsend (1983) investigates ``forecasting the forecasts of others" and finds damped oscillations $\rightarrow$ do higher-order beliefs play a role for causing oscillations in learning? If so, EE learning IRFs should exhibit no oscillations (and indeed they do not!)
\item Vector learning: are model implications different when agents learn the LOM of not only inflation but also of the other variables? $\rightarrow$ No. (Note: I'm using the same gain for all variables.)
\item Does learning both slope and constant make a difference? $\rightarrow$ Yes, in particular for constant gain learning. 2 effects: 1) less foresight, so $i$ needs to be less expansionary 2) more bumpy IRFs.
\begin{itemize}
\item[] 1) I think what might be going on here is that the only thing agents now know is $h_x$. Therefore the Ball-type ``disinflationary boom"-effect happens to a lesser extent b/c agents do not internalize movements in the interest rate in response to future inflation as much as they would otherwise (feedback from expectations is lower).
\item[] 2) More bumpy because since you're learning $b$, the loading on shocks, the specific sequence of shocks matters. Increasing the size of the cross-section, $N$, mitigates this somewhat. 
\end{itemize}
\end{enumerate}


\newpage
\subsection{IRFs from vector learning: EE and LH, $T=400, N=100$}
\begin{figure}[h!]
\subfigure[EE, dgain]{
\includegraphics[scale=\mySmallerFigScale]{\myFigPath command_IRFs_many_learning_RIR_EE_monpolconstant_onlydgain_gbar_0_145}}
\subfigure[LH, dgain]{
\includegraphics[scale=\mySmallerFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpolconstant_onlydgain_gbar_0_145}}
\subfigure[EE, cgain]{
\includegraphics[scale=\mySmallerFigScale]{\myFigPath command_IRFs_many_learning_RIR_EE_monpolconstant_onlycgain_gbar_0_145}}
\subfigure[LH, cgain]{
\includegraphics[scale=\mySmallerFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpolconstant_onlycgain_gbar_0_145}}
\caption{Learning constant only}
\end{figure}

\begin{figure}[h!]
\subfigure[EE, dgain]{
\includegraphics[scale=\mySmallerFigScale]{\myFigPath command_IRFs_many_learning_RIR_EE_monpolslope_and_constantdgain_gbar_0_145}}
\subfigure[LH, dgain]{
\includegraphics[scale=\mySmallerFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpolslope_and_constantdgain_gbar_0_145}}
\subfigure[EE, cgain]{
\includegraphics[scale=\mySmallerFigScale]{\myFigPath command_IRFs_many_learning_RIR_EE_monpolslope_and_constantcgain_gbar_0_145}}
\subfigure[LH, cgain]{
\includegraphics[scale=\mySmallerFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpolslope_and_constantcgain_gbar_0_145}}
\caption{Learning slope and constant}
\end{figure}


\subsection{A technical note on the projection facility $\blacktriangleleft$}
Contrary to Liam Graham, I never have explosive path issues for long-horizon learning, but I do sometimes for Euler-equation learning (Graham claims this is never an issue for EE learning). Graham's solution for the projection facility is to check the eigenvalues of the learning matrix $\phi$. My silly issue is that $\phi$ is not square. Therefore what I do is I check the eigenvalues of the following cheating matrix $(\phi\phi').^{1/2}$, where ``$.{1/2}$'' denotes the square root of the elements. Thoughts?

\subsection{A note on the empirical counterpart: IRFs in the data}
I note in passing that contrary to my initial priors, one possibility is that the theoretical IRFs generated by learning models actually fit empirical IRFs if the latter are properly computed. Now I base this argument not only on your oscillating IRFs from your CEE-replication, but more broadly on the discussion of computing IRFs in Valerie Ramey's handbook chapter (pointed to by Susanto):
\begin{itemize}
\item ``iterated'' forecasting vs. ``direct'' forecasting
\item[] Ramey, p. 84: ``[O]ne can forecast future values of a variable using either a horizon-specific regression (``direct'' forecasting) or iterating on a one-period ahead estimated model (``iterated'' forecasting).'' Ramey suggests that calculating an IRF from a SVAR is analogous to iterated forecasting while using \textbf{local projection} \`{a} la Jord\`{a} (2005) is analogous to direct forecasting. As pointed out by Susanto as well, using local projection to compute IRFs is likely to yield more bumpy IRFs because the direct estimation of each horizon avoids the smoothness assumption embedded in an IRF coming from a SVAR.
\item[$\rightarrow$] One battle one could fight, which however I am reluctant to fight at this point, is to argue that the tradition of smooth, non-oscillatory IRFs in the data is wrong. Nonetheless I think it's worth keeping in mind. (And at least I can hint that I've at least looked at data at one point in my life.)
\end{itemize}

\section{Bigger changes to expectation formation - so far only thoughts}
In order to dampen overshooting...
\begin{itemize}
\item Analysis in Section \ref{changes} suggests: learning should be about the slope as well, not just the constant
\item Ball (1994) suggests: learning should work in a way to decrease the movement of expectations, not to increase it $\rightarrow$ can we get anchored ``at the wrong place'' so that expectations do not move?
\item Or if expectations move just as much, we need to dampen the feedback from expectations.
\end{itemize}

What I've looked into:
\begin{itemize}
\item Bayesian learning (Gerko 2019, Collins-Dufresne et al 2016, Evans, Honkapohja \& Sargent 2016)
\begin{itemize}
\item I'm not sure if this is entirely correct, but I understand Bayesian learning to be the same as adaptive learning with the following two differences:
\begin{enumerate}
\item Initialize using priors, and update using the Kalman filter instead of least-squares
\item Can incorporate parameter uncertainty: can get around anticipated utility (although some confusion on whether this is simply an analogue of constant gain learning)
\end{enumerate}
\item The hope here is to dampen overshooting. I see some chance for it for 2 reasons:
\begin{enumerate} 
\item because the Kalman gain gives us a model-specific way of choosing the value of the constant gain, dampening the movement in expectations
\item because parameter uncertainty, if it allows me to get lower effects on future expectations than anticipated utility would, could dampen the interest rate feedback
\end{enumerate}
\item A note: Evans et al make a strange side comment: when the feedback effect from expectations is negative and sufficiently strong (in the cobweb model $\alpha < -1$) ``a possible problem of overshooting can emerge when agents overparametrize the PLM'' - oh really?????
\end{itemize}
\item Nonparametric learning (Kozlowski et al 2019)
\begin{itemize}
\item In Bayesian and LS learning, agents are learning the matrix $g_x$ which is known to be a linear, $ny \times (nx+1)$ matrix.
\item In nonparametric learning, agents instead are learning the function $g$ (in Koz et al, they are learning the distribution of shocks).
\item The recursion they use is a recursive kernel density estimator, giving $\hat{g}_t$ in period $t$.
\item So this is a frequentist approach; Orlik \& Veldkamp 2014 do the same with a Bayesian recursion, imposing a trick to avoid the particle filter (since the estimated function $f$ is potentially nonlinear).
\item Here I don't quite see how this could dampen feedback effects from expectations.
\end{itemize}
\item My overall feeling: the only way to slow down learning is to decrease the gain, so what I need to do instead is to make agents know as little as possible so they can't infer things about the Taylor rule in the future
\begin{itemize}
\item Learn $h_x$ too so you don't internalize how a shock will pan out
\item Have them not know the Taylor rule (how to do that?)
\item Put $\pi_{t-1}$ instead of $\pi_t$ in the Taylor rule, especially if agents don't know $h_x$.
\end{itemize}

\end{itemize}


\section{Changes to policy - a challenge for informational assumptions $\blacktriangleleft$ $\blacktriangleleft$}
\subsection{The big-picture issue}
The three equations of the model reproduced:
\begin{align*}
x_t &=  -\sigma i_t +\hat{\E}_t \sum_{T=t}^{\infty} \beta^{T-t }\big( (1-\beta)x_{T+1} - \sigma(\beta i_{T+1} - \pi_{T+1}) +\sigma r_T^n \big)   \\
\pi_t &= \kappa x_t +\hat{\E}_t \sum_{T=t}^{\infty} (\alpha\beta)^{T-t }\big( \kappa \alpha \beta x_{T+1} + (1-\alpha)\beta \pi_{T+1} + u_T\big)  \\
i_t &= \psi_{\pi}\pi_t + \psi_{x} x_t   + \bar{i}_t 
\end{align*}

Three extensions to the policy rule of the baseline model:
\begin{itemize}
\item $\hat{\E}_t\pi_{t+1}$ in TR instead of $\pi_t$ (``expected-inflation'')
\item $\pi_{t-1}$ in TR instead of $\pi_t$ (``lagged inflation")
\item Add $\rho i_{t-1}$ to TR (``interest rate smoothing")
\end{itemize}
It will turn out that these extensions highlight some subtle informational assumptions that will all be a variation on the following big-picture informational question:

The solution of the model takes the state-space form:
\begin{align}
X_t & = h_x X_{t-1} + \eta \varepsilon_t \label{state_eq}\\
Y_t & = g_x X_t \label{obs_eq}
\end{align}

Agents know $h_x$ and estimate $\hat{g}_x$. In terms of the model equations NKIS, NKPC and TR, what does this informational assumption imply? In particular, do agents know the relationships between the jumps, that is, do they know the three model equations, and are they thus able to impute
\begin{equation}
Y_t = A_a f_a + A_b f_b + A_s X_t ? \label{compact}
\end{equation}
I tend to think that they do \emph{not} know the NKIS and NKPC and thus cannot impute (\ref{compact}) b/c in that case they would internalize that they are identical, which we've assumed away. But they can still know the TR, in fact I think they do know the TR b/c the CB might announce it publicly.
\subsection{How the issue arises in the extensions }
The question reemerges when the extension involves introducing an endogenous state. (So the $\hat{\E}_t\pi_{t+1}$-extension is not problematic in this regard. That extension just requires rewriting the compact notation as $Y_t = A_a f_a + A_b f_b + A_s X_t +A_e\hat{\E}_t\pi_{t+1}$, where $A_e = \psi_{\pi}$, and the learning code needs to be altered to take this into account, but otherwise no drastic changes are required.)
When you introduce an endogenous state, however, like lagged inflation or lagged interest rate, then the problem emerges. 

Let me illustrate on the example of interest rate smoothing. Model equations are:
\begin{align*}
x_t &=  -\sigma i_t +\hat{\E}_t \sum_{T=t}^{\infty} \beta^{T-t }\big( (1-\beta)x_{T+1} - \sigma(\beta i_{T+1} - \pi_{T+1}) +\sigma r_T^n \big)   \\
\pi_t &= \kappa x_t +\hat{\E}_t \sum_{T=t}^{\infty} (\alpha\beta)^{T-t }\big( \kappa \alpha \beta x_{T+1} + (1-\alpha)\beta \pi_{T+1} + u_T\big)  \\
i_t &= \psi_{\pi}\pi_t + \psi_{x} x_t   + \bar{i}_t + \rho il_t \\
il_{t+1} & = i_t 
\end{align*}
The big-picture question arises in the following particular form: do agents internalize the last, linking equation between $i$ and $il$ ?
The reason this becomes important is because it has consequences for how they forecast. 2 options:
\begin{enumerate}
\item No: they treat $i$ and $il$ as two separate variables and use $h_x$ (which they know) to forecast $ il $.
\begin{itemize}
\item Advantage: Easy to solve because this means that agents do not realize that \\ \texttt{gx(end,:) = hx(end,:)}.
\item Disadvantage: Unrealistic and also has undesirable implications for dynamics b/c now you've just added another exogenous shock to the Taylor-rule that happens to have the same law of motion as $i$; no wonder I found that it didn't make a difference! (This is the approach I have taken so far from materials6 onwards for interest rate smoothing w/o realizing it.)
\end{itemize}
\item Yes: Now you're in for a curious modeling difficulty: What should agents now use to forecast $il$ and in particular $i$?
\begin{itemize}
\item If they use $h_x$ for $il$ and $g_x$ for $i$ they are inconsistent b/c they know that the variables are truly equal.
\item If they use $g_x$ for both they are forecasting suboptimally because they are not using all the information available to them. (And unfortunately, materials12f all do this!)
\item If they use $h_x$ for both then \texttt{gx(end,:)} is revealed! This is however only a problem if they are learning both constant \emph{and slope} b/c if they are only learning the constant, then  \texttt{gx(2:end,:)} is known anyway. But I just concluded in above sections that it's desirable for them to learn the slope too because it dampens shock impacts.
\end{itemize}
\end{enumerate}

\section{IRFs for baseline and 3 extensions, for 3 info assumptions}

Recap of model versions 
\begin{enumerate}
\item Baseline
\item $\hat{\E}_t\pi_{t+1}$ in TR instead of $\pi_t$ (``expected-inflation'')
\item $\pi_{t-1}$ in TR instead of $\pi_t$ (``lagged inflation")
\item Add $\rho i_{t-1}$ to TR (``interest rate smoothing")
\end{enumerate}

\noindent Recap of informational assumptions:
\begin{enumerate}
\item Forecast jump using $g_x$, endogenous state using $h_x$ (``myopic forecasters")
\item Forecast both using $g_x$ (``suboptimal forecasters")
\item Forecast both using $h_x$ (``optimal forecasters")
\end{enumerate}

\noindent Recap of which info assumption makes a difference for which extension
\begin{enumerate}
\item Baseline $\rightarrow$ same for all
\item $\hat{\E}_t\pi_{t+1}$ in TR instead of $\pi_t$ (``expected-inflation'') $\rightarrow$ same for all
\item $\pi_{t-1}$ in TR instead of $\pi_t$ (``lagged inflation") $\rightarrow$ info assumptions matter, have implemented only (2) and (3)
\item Add $\rho i_{t-1}$ to TR (``interest rate smoothing") $\rightarrow$ info assumptions matter, have implemented all
\end{enumerate}

\newpage
\noindent Overview of plots - all plots LH, constant gain vector learning, monetary policy shock imposed at $t=25$.
\begin{enumerate}
\item Baseline
	\begin{enumerate}
	\item Learning constant only
	\item Learning slope and constant
	\end{enumerate}
\item $\hat{\E}_t\pi_{t+1}$ in TR instead of $\pi_t$ (``expected-inflation'')
	\begin{enumerate}
	\item Learning constant only
	\item Learning slope and constant
	\end{enumerate}
\item $\pi_{t-1}$ in TR instead of $\pi_t$ (``lagged inflation")
	\begin{enumerate}
	\item Forecast both using $g_x$ (``suboptimal forecasters")
		\begin{enumerate}
		\item Learning constant only
		\item Learning slope and constant
		\end{enumerate}
	\item Forecast both using $h_x$ (``optimal forecasters")
		\begin{enumerate}
		\item Learning constant only
		\item Learning slope and constant
		\end{enumerate}
	\end{enumerate}

\item $\rho i_{t-1}$ in TR (``interest rate smoothing") with $\rho=0.6$
\begin{enumerate}
\item Forecast jump using $g_x$, endogenous state using $h_x$ (``myopic forecasters")
\begin{enumerate}
\item Learning constant only
\item Learning slope and constant
\end{enumerate}
\item Forecast both using $g_x$ (``suboptimal forecasters")
\begin{enumerate}
\item Learning constant only
\item Learning slope and constant
\end{enumerate}
\item Forecast both using $h_x$ (``optimal forecasters")
\begin{enumerate}
\item Learning constant only
\item Learning slope and constant
\end{enumerate}
\end{enumerate}

\end{enumerate}
\newpage
\subsection{Baseline and $\hat{\E}_t\pi_{t+1}$ in TR figures}

\begin{figure}[h!]
\subfigure[Learning constant only]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpol_cgain_gbar_0_145_baseline_myopic_constant_only}}
\subfigure[Learning slope and constant]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpol_cgain_gbar_0_145_baseline_myopic_slope_and_constant}}
\caption{Baseline}
\end{figure}

\begin{figure}[h!]
\subfigure[Learning constant only]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpol_cgain_gbar_0_145_Epi_suboptimal_fcst_constant_only}}
\subfigure[Learning slope and constant]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpol_cgain_gbar_0_145_Epi_suboptimal_fcst_slope_and_constant}}
\caption{$\hat{\E}_t\pi_{t+1}$ in TR}
\end{figure}

\clearpage

\newpage
\subsection{$\pi_{t-1}$ in TR figures}

\begin{figure}[h!]
\subfigure[Learning constant only]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpol_cgain_gbar_0_145_pil_myopic_constant_only}}
\subfigure[Learning slope and constant]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpol_cgain_gbar_0_145_pil_myopic_slope_and_constant}}
\caption{$\pi_{t-1}$ in TR, forecasting using $g_x$ for jump, $h_x$ for state}
\end{figure}

\begin{figure}[h!]
\subfigure[Learning constant only]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpol_cgain_gbar_0_145_pil_suboptimal_fcst_constant_only}}
\subfigure[Learning slope and constant]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpol_cgain_gbar_0_145_pil_suboptimal_fcst_slope_and_constant}}
\caption{$\pi_{t-1}$ in TR, forecasting using $g_x$ for both}
\end{figure}

\begin{figure}[h!]
\subfigure[Learning constant only]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpol_cgain_gbar_0_145_pil_optimal_fcst_constant_only}}
\subfigure[Learning slope and constant]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpol_cgain_gbar_0_145_pil_optimal_fcst_slope_and_constant}}
\caption{$\pi_{t-1}$ in TR, forecasting using $h_x$ for both}
\end{figure}

\clearpage

\newpage
\subsection{$\rho i_{t-1}$ in TR figures}

\begin{figure}[h!]
\subfigure[Learning constant only]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpol_cgain_gbar_0_145_old_intrate_smoothing_myopic_constant_only}}
\subfigure[Learning slope and constant]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpol_cgain_gbar_0_145_old_intrate_smoothing_myopic_slope_and_constant}}
\caption{$\rho i_{t-1}$ in TR, forecasting using $g_x$ for jump, $h_x$ for state}
\end{figure}

\begin{figure}[h!]
\subfigure[Learning constant only]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpol_cgain_gbar_0_145_il_suboptimal_fcst_constant_only}}
\subfigure[Learning slope and constant]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpol_cgain_gbar_0_145_il_suboptimal_fcst_slope_and_constant}}
\caption{$\rho i_{t-1}$ in TR, forecasting using $g_x$ for both}
\end{figure}

\begin{figure}[h!]
\subfigure[Learning constant only]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpol_cgain_gbar_0_145_il_optimal_fcst_constant_only}}
\subfigure[Learning slope and constant]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath command_IRFs_many_learning_RIR_LH_monpol_cgain_gbar_0_145_il_optimal_fcst_slope_and_constant}}
\caption{$\rho i_{t-1}$ in TR, forecasting using $h_x$ for both}
\end{figure}

\end{document}





