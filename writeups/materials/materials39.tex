\documentclass[11pt]{article}
\usepackage{amsmath, amsthm, amssymb,lscape, natbib}
\usepackage{mathtools}
\usepackage{subfigure}
\usepackage[font=footnotesize,labelfont=bf]{caption}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{hhline}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{setspace}
\usepackage[final]{pdfpages}
\usepackage[left=2.5cm,top=2.5cm,right=2.5cm, bottom=2.5cm]{geometry}
\usepackage{natbib} 
\usepackage{bibentry} 
\newcommand{\bibverse}[1]{\begin{verse} \bibentry{#1} \end{verse}}
\newcommand{\vs}{\vspace{.3in}}
\renewcommand{\ni}{\noindent}
\usepackage{xr-hyper}
\usepackage[]{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}
 
\urlstyle{same}
\usepackage[capposition=top]{floatrow}
\usepackage{amssymb}
\usepackage{relsize}
\usepackage[dvipsnames]{xcolor}
\usepackage{fancyhdr}
\usepackage{tikz}
 
\pagestyle{fancy} % customize header and footer
\fancyhf{} % clear initial header and footer
%\rhead{Overleaf}
\lhead{\centering \rightmark} % this adds subsection number and name
\lfoot{\centering \rightmark} 
\rfoot{\thepage} % put page number (the centering command puts it in the middle, don't matter if you put it in right or left footer)

\def \myFigPath {../../figures/} 
% BE CAREFUL WITH FIGNAMES, IN LATEX THEY'RE NOT CASE SENSITIVE!!
\def \myTablePath {../../tables/} 

%\definecolor{mygreen}{RGB}{0, 100, 0}
\definecolor{mygreen}{RGB}{0, 128, 0}

\definecolor{citec}{rgb}{0,0,.5}
\definecolor{linkc}{rgb}{0,0,.6}
\definecolor{bcolor}{rgb}{1,1,1}
\hypersetup{
%hidelinks = true
  colorlinks = true,
  urlcolor=linkc,
  linkcolor=linkc,
  citecolor = citec,
  filecolor = linkc,
  pdfauthor={Laura G\'ati},
}


\geometry{left=.83in,right=.89in,top=1in,
bottom=1in}
\linespread{1.5}
\renewcommand{\[}{\begin{equation}}
\renewcommand{\]}{\end{equation}}

% New Options
\newtheorem{prop}{Proposition}
\newtheorem{definition}{Definition}[section]
\newtheorem*{remark}{Remark}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{conjecture}{Conjecture}

%\newtheorem{theorem}{Theorem}[section] % the third argument specifies that their number will be adopted to the section
%\newtheorem{corollary}{Corollary}[theorem]
%\newtheorem{lemma}[theorem]{Lemma}
%\declaretheorem{proposition}
%\linespread{1.3}
%\raggedbottom
%\font\reali=msbm10 at 12pt

% New Commands
\newcommand{\real}{\hbox{\reali R}}
\newcommand{\realp}{\hbox{\reali R}_{\scriptscriptstyle +}}
\newcommand{\realpp}{\hbox{\reali R}_{\scriptscriptstyle ++}}
\newcommand{\R}{\mathbb{R}}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\argmin}{arg\,min}
\newcommand\w{3.0in}
\newcommand\wnum{3.0}
\def\myFigWidth{5.3in}
\def\mySmallerFigWidth{2.1in}
\def\myEvenBiggerFigScale{0.8}
\def\myPointSixFigScale{0.6}
\def\myBiggerFigScale{0.4}
\def\myFigScale{0.3}
\def\myMediumFigScale{0.25}
\def\mySmallFigScale{0.22}
\def\mySmallerFigScale{0.18}
\def\myTinyFigScale{0.16}
\def\myPointFourteenFigScale{0.14}
\def\myTinierFigScale{0.12}
\def\myAdjustableFigScale{0.16}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}} % this defines a command to make align only number this line
\newcommand{\code}[1]{\texttt{#1}} %code %

\renewcommand*\contentsname{Overview}
\setcounter{tocdepth}{2}

% define a command to make a huge question mark (it works in math mode)
\newcommand{\bigqm}[1][1]{\text{\larger[#1]{\textbf{?}}}}

% use package and define command to add blank page
\usepackage{afterpage}
\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \addtocounter{page}{-1}%
    \newpage}

\begin{document}

\linespread{1.0}

\title{Materials 39 - Combing through the code for bugs}
\author{Laura G\'ati} 
\date{\today}
\maketitle

%%%%%%%%%%%%%%%%%%%%             DOCUMENT           %%%%%%%%%%%%%%%%%% 

\tableofcontents

%\listoffigures

\newpage

\section{Look into measurement error}

\subsection{Autocovariograms w/ and w/o measurement error, not using expectations data}
%\clearpage
\begin{figure}[h!]
\subfigure[\colorbox{yellow}{w/o measurement error } \newline nearly = Fig. 1 of Materials 37, loss $\approx 787$ ]{\includegraphics[scale=0.2]{\myFigPath alphas_constant_only_pi_only_N_100_nfe_5femax_2_loss_787_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nestimations_scaleW_0_use_expectations_0_use_meas_error_0_command_GMM_LOMgain_univariate_05_Aug_2020}}
\subfigure[\colorbox{yellow}{w/o measurement error } ]{\includegraphics[scale=0.22]{\myFigPath autocovariogram_sim_constant_only_pi_only_N_100_nfe_5femax_2_loss_787_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nestimations_scaleW_0_use_expectations_0_use_meas_error_0_command_GMM_LOMgain_univariate_05_Aug_2020}}
%\subfigure[\colorbox{yellow}{with measurement error } , loss $\approx 18533$]{\includegraphics[scale=0.2]{\myFigPath alphas_constant_only_pi_only_N_100_nfe_5femax_2_loss_18533_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nestimations_scaleW_0_use_expectations_0_use_meas_error_1_command_GMM_LOMgain_univariate_04_Aug_2020}}
%\subfigure[\colorbox{yellow}{with measurement error (in estimation only)} ]{\includegraphics[scale=0.22]{\myFigPath autocovariogram_sim_constant_only_pi_only_N_100_nfe_5femax_2_loss_18533_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nestimations_scaleW_0_use_expectations_0_use_meas_error_1_command_GMM_LOMgain_univariate_04_Aug_2020}}
\subfigure[\colorbox{yellow}{with measurement error }, loss $\approx 0$ ]{\includegraphics[scale=0.2]{\myFigPath alphas_constant_only_pi_only_N_100_nfe_5femax_2_loss_0_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nestimations_scaleW_0_use_expectations_0_use_meas_error_1_command_GMM_LOMgain_univariate_04_Aug_2020}}
\subfigure[\colorbox{yellow}{with measurement error (in true data and in estimation)} ]{\includegraphics[scale=0.22]{\myFigPath autocovariogram_sim_constant_only_pi_only_N_100_nfe_5femax_2_loss_0_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nestimations_scaleW_0_use_expectations_0_use_meas_error_1_command_GMM_LOMgain_univariate_04_Aug_2020}}
\caption{$N=100$, w/o expectations data, \colorbox{yellow}{estimate moments N times (N estimations)}, imposing convexity with weight 100K, truth with $nfe=5, fe \in(-2,2)$}
\end{figure}

The measurement error definitely shows up. 
\begin{itemize}
\item It should change the true moments, b/c those are just one simulation.
\item For N estimations, it should change the initial moments, and it does.
\end{itemize}

\clearpage 

\begin{figure}[h!]
\subfigure[\colorbox{yellow}{w/o measurement error }, loss $\approx 944$ ]{\includegraphics[scale=0.2]{\myFigPath alphas_constant_only_pi_only_N_100_nfe_5femax_2_loss_944_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nsimulations_scaleW_0_use_expectations_0_use_meas_error_0_command_GMM_LOMgain_univariate_04_Aug_2020}}
\subfigure[\colorbox{yellow}{w/o measurement error } ]{\includegraphics[scale=0.22]{\myFigPath autocovariogram_sim_constant_only_pi_only_N_100_nfe_5femax_2_loss_944_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nsimulations_scaleW_0_use_expectations_0_use_meas_error_0_command_GMM_LOMgain_univariate_04_Aug_2020}}
%\subfigure[\colorbox{yellow}{with measurement error } , loss $\approx 23532$]{\includegraphics[scale=0.2]{\myFigPath alphas_constant_only_pi_only_N_100_nfe_5femax_2_loss_23532_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nsimulations_scaleW_0_use_expectations_0_use_meas_error_1_command_GMM_LOMgain_univariate_04_Aug_2020}}
%\subfigure[\colorbox{yellow}{with measurement error (in estimation only)} ]{\includegraphics[scale=0.22]{\myFigPath autocovariogram_sim_constant_only_pi_only_N_100_nfe_5femax_2_loss_23532_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nsimulations_scaleW_0_use_expectations_0_use_meas_error_1_command_GMM_LOMgain_univariate_04_Aug_2020}}
\subfigure[\colorbox{yellow}{with measurement error }, loss $\approx 0$ ]{\includegraphics[scale=0.2]{\myFigPath alphas_constant_only_pi_only_N_100_nfe_5femax_2_loss_0_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nsimulations_scaleW_0_use_expectations_0_use_meas_error_1_command_GMM_LOMgain_univariate_04_Aug_2020}}
\subfigure[\colorbox{yellow}{with measurement error (in true data and in estimation)} ]{\includegraphics[scale=0.22]{\myFigPath autocovariogram_sim_constant_only_pi_only_N_100_nfe_5femax_2_loss_0_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nsimulations_scaleW_0_use_expectations_0_use_meas_error_1_command_GMM_LOMgain_univariate_04_Aug_2020}}
\caption{$N=100$, w/o expectations data, \colorbox{yellow}{estimate mean moments once (N simulations)}, imposing convexity with weight 100K, truth with $nfe=5, fe \in(-2,2)$}
\end{figure}

\begin{itemize}
\item For N simulations, it shouldn't change the initial moments, and it doesn't either.
\item But it shouldn't affect the procedure's ability to match the moments. It does though.
\item A phenomenon I also can't explain is why losses become orders of magnitude smaller just by using the data that was generated with measurement error in it.
\end{itemize}

\clearpage

\subsubsection{Put expectations back in: w/ measurement error, or w/o}
\begin{figure}[h!]
\subfigure[\colorbox{yellow}{w/o measurement error }, loss $\approx5243$ ]{\includegraphics[scale=0.18]{\myFigPath alphas_constant_only_pi_only_N_100_nfe_5femax_2_loss_5243_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nsimulations_scaleW_0_use_expectations_1_use_meas_error_0_command_GMM_LOMgain_univariate_04_Aug_2020}}
\subfigure[\colorbox{yellow}{w/o measurement error } ]{\includegraphics[scale=0.27]{\myFigPath autocovariogram_sim_constant_only_pi_only_N_100_nfe_5femax_2_loss_5243_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nsimulations_scaleW_0_use_expectations_1_use_meas_error_0_command_GMM_LOMgain_univariate_04_Aug_2020}}
\subfigure[\colorbox{yellow}{with measurement error }, loss $\approx 0$ This figure is Fig 3 from Materials 38]{\includegraphics[scale=0.18]{\myFigPath alphas_constant_only_pi_only_N_100_nfe_5_loss_0_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nsimulations_command_GMM_LOMgain_univariate_25_Jul_2020}}
\subfigure[\colorbox{yellow}{with measurement error (in true data and in estimation)} ]{\includegraphics[scale=0.27]{\myFigPath autocovariogram_sim_constant_only_pi_only_N_100_nfe_5_loss_0_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nsimulations_command_GMM_LOMgain_univariate_25_Jul_2020}}
\caption{$N=100$, w/ expectations data, \colorbox{yellow}{estimate mean moments once (N simulations)}, imposing convexity with weight 100K, truth with $nfe=5, fe \in(-2,2)$}
\end{figure}

Clearly the measurement error is responsible for the misses!

\clearpage
\subsection{Loss for holding $\alpha$s at true values, and varying one at a time}

\subsubsection{Reference: materials 38}
\begin{figure}[h!]
\subfigure[\colorbox{yellow}{Rescale W}]{\includegraphics[scale=0.35]{\myFigPath loss_for_indi_alphas_others_at_true_constant_only_pi_only_N_100_nfe_5_loss_0_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nsimulations_command_GMM_LOMgain_univariate_28_Jul_2020}}
\subfigure[\colorbox{yellow}{Don't rescale W} (Rescaling but dropping the convexity moment looks like this too, except the order of magnitude is $10^{-5}$)]{\includegraphics[scale=0.35]{\myFigPath loss_for_indi_alphas_others_at_true_dontrescale_constant_only_pi_only_N_100_nfe_5_loss_0_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nsimulations_command_GMM_LOMgain_univariate_28_Jul_2020}}
\caption{Loss for $N=100$, incl. 1-step ahead forecasts of inflation, \colorbox{yellow}{estimate mean moments once (N simulations)}, imposing convexity with weight 100K, with measurement error imposed, truth with $nfe=5, fe \in(-2,2)$}
\end{figure}


\subsubsection{Loss when not using expectations data, all else same as Materials 38}
\begin{figure}[h!]
\subfigure[\colorbox{yellow}{w/o measurement error}]{\includegraphics[scale=0.32]{\myFigPath loss_for_indi_alphas_others_at_true_dontrescale_constant_only_pi_only_N_100_nfe_5femax_2_loss_0_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nsimulations_scaleW_0_use_expectations_0_use_meas_error_0_command_GMM_LOMgain_univariate_04_Aug_2020}}
\subfigure[\colorbox{yellow}{with measurement error imposed in true data and in estimation} ]{\includegraphics[scale=0.32]{\myFigPath loss_for_indi_alphas_others_at_true_dontrescale_constant_only_pi_only_N_100_nfe_5femax_2_loss_0_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nsimulations_scaleW_0_use_expectations_0_use_meas_error_1_command_GMM_LOMgain_univariate_04_Aug_2020}}
\caption{Loss for $N=100$, \colorbox{yellow}{NOT} using 1-step ahead forecasts of inflation, estimate mean moments once, imposing convexity with weight 100K, , truth with $nfe=5, fe \in(-2,2)$}
\end{figure}
Note: If I don't use expectations variables, the tiny $W$ issue disappears. So those are the moments that cause the rescaling issue in the first place. Therefore I'm not rescaling here.

\begin{figure}[h!]
\subfigure[\colorbox{yellow}{w/o measurement error}]{\includegraphics[scale=0.32]{\myFigPath loss_for_indi_alphas_others_at_true_dontrescale_constant_only_pi_only_N_100_nfe_5femax_2_loss_5243_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nsimulations_scaleW_0_use_expectations_1_use_meas_error_0_command_GMM_LOMgain_univariate_04_Aug_2020}}
\caption{Loss for $N=100$, \colorbox{yellow}{using 1-step ahead forecasts of inflation}, estimate mean moments once, imposing convexity with weight 100K, , truth with $nfe=5, fe \in(-2,2)$}
\end{figure}

\begin{itemize}
\item the 0-forecast-error $\alpha$ was reversed
\item also reversed: now middle $\alpha$s identified, although a little too low, but the sides don't seem so
\end{itemize}

\newpage
\subsubsection{Get rid of $k^{-1}$ in learning code, just use $k$ (``uninvert $k$'')}

\begin{figure}[h!]
\subfigure[\colorbox{yellow}{estimate moments N times (N estimations)}, loss $\approx 740$ ]{\includegraphics[scale=0.2]{\myFigPath alphas_constant_only_pi_only_N_100_nfe_5femax_2_loss_740_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nestimations_scaleW_0_use_expectations_0_use_meas_error_0_command_GMM_LOMgain_univariate_05_Aug_2020}}
\subfigure[]{\includegraphics[scale=0.22]{\myFigPath autocovariogram_sim_constant_only_pi_only_N_100_nfe_5femax_2_loss_740_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nestimations_scaleW_0_use_expectations_0_use_meas_error_0_command_GMM_LOMgain_univariate_05_Aug_2020}}
\subfigure[\colorbox{yellow}{estimate mean moments once (N simulations)}, loss $\approx 944$ ]{\includegraphics[scale=0.2]{\myFigPath alphas_constant_only_pi_only_N_100_nfe_5femax_2_loss_944_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nsimulations_scaleW_0_use_expectations_0_use_meas_error_0_command_GMM_LOMgain_univariate_05_Aug_2020}}
\subfigure[]{\includegraphics[scale=0.22]{\myFigPath autocovariogram_sim_constant_only_pi_only_N_100_nfe_5femax_2_loss_944_gridspacing_uniform_Wdiffs2_100000_Wmid_0_Nsimulations_scaleW_0_use_expectations_0_use_meas_error_0_command_GMM_LOMgain_univariate_05_Aug_2020}}
\caption{$N=100$, w/o expectations data, w/o measurement error, imposing convexity with weight 100K, truth with $nfe=5, fe \in(-2,2)$}
\end{figure}
%%%%%%%%%%%               BLANK   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% adds blank page
\afterpage{\blankpage}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%                                              APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \clearpage
%    \newpage
\appendix
% the following command makes equation numbering include the section first, but just for what follows
\numberwithin{equation}{section}
\section{Model summary}

\vspace{-0.5cm}

\begin{align}
x_t &=  -\sigma i_t +\hat{\E}_t \sum_{T=t}^{\infty} \beta^{T-t }\big( (1-\beta)x_{T+1} - \sigma(\beta i_{T+1} - \pi_{T+1}) +\sigma r_T^n \big)  \label{A1}  \\
\pi_t &= \kappa x_t +\hat{\E}_t \sum_{T=t}^{\infty} (\alpha\beta)^{T-t }\big( \kappa \alpha \beta x_{T+1} + (1-\alpha)\beta \pi_{T+1} + u_T\big) \label{A2}  \\
i_t &= \psi_{\pi}\pi_t + \psi_{x} x_t  + \bar{i}_t \label{TR} \quad \quad (\text{if imposed})
\end{align}

\vspace{-1.2cm}

\begin{align}
\text{PLM:} \quad \quad & \hat{\E}_t z_{t+h}  =  a_{t-1} + bh_x^{h-1}s_t  \quad \forall h\geq 1 \quad \quad b = g_x\; h_x \quad \quad  \label{PLM} \\
\text{Updating:} \quad \quad & a_{t}  =a_{t-1} +k_t^{-1}\big(z_{t} -(a_{t-1}+b s_{t-1}) \big)  \label{A5} \\
\text{Anchoring function:} \quad \quad & k^{-1}_t  = \rho_k k^{-1}_{t-1} + \gamma_k fe_{t-1}^2 \label{A6}\\
\text{Forecast error:} \quad \quad & fe_{t-1}  = z_t - (a_{t-1}+b s_{t-1}) \label{A7} \\
\text{LH expectations:} \quad \quad & f_a(t) = \frac{1}{1-\alpha\beta}a_{t-1}  + b(\mathbb{I}_{nx} - \alpha\beta h)^{-1}s_t \quad \quad  f_b(t) = \frac{1}{1-\beta}a_{t-1}  + b(\mathbb{I}_{nx} - \beta h)^{-1}s_t  \label{A8}
\end{align}

\vspace{-0.5cm}

This notation captures vector learning ($z$ learned) for intercept only. For scalar learning, $a_t= \begin{pmatrix} \bar{\pi}_t & 0 & 0\end{pmatrix}' $ and $b_1$ designates the first row of $b$. The observables $(\pi, x)$ are determined as:
\begin{align}
x_t &=  -\sigma i_t + \begin{bmatrix} \sigma & 1-\beta & -\sigma\beta \end{bmatrix} f_b + \sigma \begin{bmatrix} 1 & 0 & 0 \end{bmatrix} (\mathbb{I}_{nx} - \beta h_x)^{-1} s_t \label{A9} \\
\pi_t &= \kappa x_t  + \begin{bmatrix} (1-\alpha)\beta & \kappa\alpha\beta & 0 \end{bmatrix}  f_a + \begin{bmatrix} 0 & 0 & 1 \end{bmatrix}  (\mathbb{I}_{nx} - \alpha \beta h_x)^{-1}  s_t \label{A10}
\end{align}

\section{Target criterion}\label{target_crit_levels}
The target criterion in the simplified model (scalar learning of inflation intercept only, $k_t^{-1} = \mathbf{g}(fe_{t-1})$):
\begin{align*}
\pi_t  = -\frac{\lambda_x}{\kappa}\bigg\{x_t - \frac{(1-\alpha)\beta}{1-\alpha\beta} \bigg(k_t^{-1}+((\pi_t - \bar{\pi}_{t-1}-b_1 s_{t-1}))\mathbf{g}_{\pi}(t) \bigg) \\
\bigg(\E_t\sum_{i=1}^{\infty}x_{t+i}\prod_{j=0}^{i-1}(1-k_{t+1+j}^{-1} - (\pi_{t+1+j} - \bar{\pi}_{t+j}-b_1 s_{t+j})\mathbf{g_{\bar{\pi}}}(t+j)) \bigg)
\bigg\} \numberthis \label{target}
\end{align*}
where I'm using the notation that $\prod_{j=0}^{0} \equiv 1$. For interpretation purposes, let me rewrite this as follows:
\begin{align*}
\pi_t  = & \; \textcolor{red}{-\frac{\lambda_x}{\kappa} x_t} \textcolor{blue}{ \; + \frac{\lambda_x}{\kappa} \frac{(1-\alpha)\beta}{1-\alpha\beta} \bigg(k_t^{-1}+ fe^{eve}_{t|t-1}\mathbf{g}_{\pi}(t) \bigg)\E_t\sum_{i=1}^{\infty}x_{t+i}}  \\
& \textcolor{mygreen}{- \frac{\lambda_x}{\kappa} \frac{(1-\alpha)\beta}{1-\alpha\beta} \bigg(k_t^{-1}+ fe^{eve}_{t|t-1}\mathbf{g}_{\pi}(t) \bigg) \bigg(\E_t\sum_{i=1}^{\infty}x_{t+i}\prod_{j=0}^{i-1}(k_{t+1+j}^{-1} + fe^{eve}_{t+1+j|t+j})\mathbf{g_{\bar{\pi}}}(t+j) \bigg)}
\numberthis \label{target_interpretation}
\end{align*}
Interpretation: \textcolor{red}{tradeoffs from discretion in RE} + \textcolor{blue}{effect of current level and change of the gain on future tradeoffs} + \textcolor{mygreen}{effect of future expected levels and changes of the gain on future tradeoffs}

%\section{A target criterion system for an anchoring function specified for gain changes}\label{target_crit_changes}
%\begin{equation}
%k_t = k_{t-1} + \mathbf{g}(fe_{t|t-1})
%\end{equation}
%Turns out the $k_{t-1}$ adds one $\varphi_{6,t+1}$ too many which makes the target criterion unwieldy. The FOCs of the Ramsey problem are
%\begin{align}
%& 2\pi_t + 2\frac{\lambda}{\kappa}x_t -k_t^{-1} \varphi_{5,t} - \mathbf{g}_{\pi}(t)\varphi_{6,t}  = 0 \label{gaspar22}\\
%& c x_{t+1} + \varphi_{5,t} -(1-k_t^{-1})\varphi_{5,t+1} +\mathbf{g}_{\bar{\pi}}(t)\varphi_{6,t+1} = 0 \label{gaspar21}\\
%& \varphi_{6,t} \; \textcolor{red}{+\; \varphi_{6,t+1}} = fe_t \varphi_{5,t} \label{constraints}
%\end{align}
%where the red multiplier is the new element vis-a-vis the case where the anchoring function is specified in levels ($k_t^{-1} = \mathbf{g}(fe_{t-1})$, as in App. \ref{target_crit_levels}), and I'm using the shorthand notation
%\begin{align}
%c & = -\frac{2(1-\alpha)\beta}{1-\alpha\beta}\frac{\lambda}{\kappa} \\ 
%fe_t & = \pi_t - \bar{\pi}_{t-1}-b s_{t-1}
%\end{align}
%(\ref{gaspar22}) says that in anchoring, the discretion tradeoff is complemented with tradeoffs coming from learning ($\varphi_{5,t}$), which are more binding when expectations are unanchored ($k_{t}^{-1}$ high). Moreover, the change in the anchoring of expectations imposes an additional constraint ($\varphi_{6,t}$), which is more strongly binding if the gain responds strongly to inflation ($\mathbf{g}_{\pi}(t)$).
%One can simplify this three-equation-system to:
%\begin{align}
%\varphi_{6,t} & = -c fe_t x_{t+1} + \bigg(1+ \frac{fe_t}{fe_{t+1}}(1-k_{t+1}^{-1}) -fe_t \mathbf{g}_{\bar{\pi}}(t) \bigg) \varphi_{6,t+1} -\frac{fe_t}{fe_{t+1}}(1-k_{t+1}^{-1})\varphi_{6,t+2}\label{6'} \\
%0 & = 2\pi_t + 2\frac{\lambda}{\kappa}x_t   - \bigg( \frac{k_t^{-1}}{fe_t} + \mathbf{g}_{\pi}(t)\bigg)\varphi_{6,t} + \frac{k_t^{-1}}{fe_t}\varphi_{6,t+1}\label{1'}
%\end{align}
%Unfortunately, I haven't been able to solve (\ref{6'}) for $\varphi_{6,t}$ and therefore I can't express the target criterion so nicely as before. The only thing I can say is to direct the targeting rule-following central bank to compute $\varphi_{6,t}$ as the solution to (\ref{1'}), and then evaluate (\ref{6'}) as a target criterion. The solution to (\ref{1'}) is given by:
%\begin{equation}
%\varphi_{6,t} = -2\E_t\sum_{i=0}^{\infty}(\pi_{t+i}+\frac{\lambda_x}{\kappa}x_{t+i})\prod_{j=0}^{i-1}\frac{\frac{k_{t+j}^{-1}}{fe_{t+j}}}{\frac{k_{t+j}^{-1}}{fe_{t+j}} + \mathbf{g}_{\pi}(t+j)} \label{sol1'}
%\end{equation}
%Interpretation: the anchoring constraint is not binding ($\varphi_{6,t}=0$) if the CB always hits the target (
%$\pi_{t+i}+\frac{\lambda_x}{\kappa}x_{t+i} = 0 \quad \forall i$); or expectations are always anchored ($k_{t+j}^{-1}=0 \quad \forall j$). 



%%%%%%%%%%     IRFS                %%%%%%%%%%%%%%%%
\clearpage
\section{Impulse responses to iid monpol shocks across a wide range of learning models}
$T=400, N=100, n_{drop}=5,$ shock imposed at $t=25$, calibration as above, Taylor rule assumed to be known, PLM = learn constant only, of inflation only.

\begin{figure}[h!]
\subfigure[Decreasing gain learning]{\includegraphics[scale=\myTinyFigScale]{\myFigPath command_IRFs_approx_pretty_RIR_LH_monpol_dgain_constant_only_pi_only_2020_07_07}}
\hfill
\subfigure[Mean gain]{\includegraphics[scale=\myTinyFigScale]{\myFigPath command_IRFs_approx_pretty_invgain_dgain_constant_only_pi_only_params_psi_pi_1_5_psi_x_0_gbar_0_145_thetbar_16_thettilde_2_5_kap_0_8_lamx_0_05_lami_0_2020_07_07}}
\subfigure[Constant gain learning]{\includegraphics[scale=\myTinyFigScale]{\myFigPath command_IRFs_approx_pretty_RIR_LH_monpol_cgain_constant_only_pi_only_2020_07_07}}
\hfill
\subfigure[Mean gain]{\includegraphics[scale=\myTinyFigScale]{\myFigPath command_IRFs_approx_pretty_invgain_cgain_constant_only_pi_only_params_psi_pi_1_5_psi_x_0_gbar_0_145_thetbar_16_thettilde_2_5_kap_0_8_lamx_0_05_lami_0_2020_07_07}}
\subfigure[CEMP criterion (vector)]{\includegraphics[scale=\myTinyFigScale]{\myFigPath command_IRFs_approx_pretty_RIR_LH_monpol_again_critCEMP_constant_only_pi_only_2020_07_07}}
\hfill
\subfigure[Mean gain]{\includegraphics[scale=\myTinyFigScale]{\myFigPath command_IRFs_approx_pretty_invgain_again_critCEMP_constant_only_pi_only_params_psi_pi_1_5_psi_x_0_gbar_0_145_thetbar_16_thettilde_2_5_kap_0_8_lamx_0_05_lami_0_2020_07_07}}
\caption{IRFs and gain history (sample means) }
\end{figure}


\begin{figure}[h!]
\subfigure[CUSUM criterion (vector)]{\includegraphics[scale=\myTinyFigScale]{\myFigPath command_IRFs_approx_pretty_RIR_LH_monpol_again_critCUSUM_constant_only_pi_only_2020_07_07}}
\hfill
\subfigure[Mean gain]{\includegraphics[scale=\myTinyFigScale]{\myFigPath command_IRFs_approx_pretty_invgain_again_critCUSUM_constant_only_pi_only_params_psi_pi_1_5_psi_x_0_gbar_0_145_thetbar_16_thettilde_2_5_kap_0_8_lamx_0_05_lami_0_2020_07_07}}
\subfigure[Smooth criterion, approximated, using $\alpha^{true}= (0.05;0.025;0;0.025;0.05)$, on $fe \in (-2,2)$.]{\includegraphics[scale=\myTinyFigScale]{\myFigPath command_IRFs_approx_pretty_RIR_LH_monpol_again_critsmooth_constant_only_pi_only_2020_07_07}}
\hfill
\subfigure[Mean gain]{\includegraphics[scale=\myTinyFigScale]{\myFigPath command_IRFs_approx_pretty_invgain_again_critsmooth_constant_only_pi_only_params_psi_pi_1_5_psi_x_0_gbar_0_145_thetbar_16_thettilde_2_5_kap_0_8_lamx_0_05_lami_0_2020_07_07}}

\caption{IRFs and gain history (sample means), continued }
\end{figure}


\end{document}

%%%%%%%%%%%%%    SUBFIGURE  %%%%%%%%%%%
%\begin{figure}[h!]
%\subfigure[Hodrick-Prescott, $\lambda=1600$]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath materials22_gain_dhat_HP}}
%\hfill % this is great to intro dpace between subfigures
%\subfigure[Hamilton, 4 lags, $h=8$]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath materials22_gain_dhat_Hamilton}}
%\subfigure[Baxter-King, $(6,32)$ quarters, truncation at 12 lags]{\includegraphics[scale=\myAdjustableFigScale]{\myFigPath materials22_gain_dhat_BK}}
%\caption{Inverse gain for $\hat{d}$ for the different filters}
%\end{figure}

%%%%%%%%%%%%%    TABLE  %%%%%%%%%%%
%\begin{center}
%\begin{table}[h!]
%\caption{$\hat{d}$}
%\begin{tabular}{ c |c |c }
%  & $W = I$ & $W = \text{diag}(\hat{\sigma}_{ac(0)}, \dots, \hat{\sigma}_{ac(K)})$ \\ 
%  \hline
% HP & 77.7899 & 10 \\  
% \hline
% Hamilton & 32.1649 & 10 \\  
% \hline
% BK & 90.3929 & 10    
%\end{tabular}
%\end{table}
%\end{center}





